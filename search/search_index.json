{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>This is the documentation</p>"},{"location":"examples/compute_nh/","title":"$N_H$ computation","text":"In\u00a0[1]: Copied! <pre>import astropy.units as u\nfrom xsb_fluc.data.cluster import Cluster\n\ncluster = Cluster(\n    imglink='data/A2142/mosaic_a2142.fits.gz',\n    explink='data/A2142/mosaic_a2142_expo.fits.gz',\n    bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',\n    reglink='data/A2142/src_ps.reg',\n    nhlink='data/A2142/A2142_nh.fits',\n    ra=239.58615,\n    dec=27.229433,\n    r_500=1.403*u.Mpc, \n    redshift=0.09,\n)\n</pre> import astropy.units as u from xsb_fluc.data.cluster import Cluster  cluster = Cluster(     imglink='data/A2142/mosaic_a2142.fits.gz',     explink='data/A2142/mosaic_a2142_expo.fits.gz',     bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',     reglink='data/A2142/src_ps.reg',     nhlink='data/A2142/A2142_nh.fits',     ra=239.58615,     dec=27.229433,     r_500=1.403*u.Mpc,      redshift=0.09, ) <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> <p>In the following cell, I show how to obtain a column density absorption map using the HI4PI survey (https://cade.irap.omp.eu/dokuwiki/doku.php?id=hi4pi). As the survey is provided in an Healpix file, it is very convenient to use. Reprojecting the $N_H$ map on an image is as easy as the following cell.</p> In\u00a0[2]: Copied! <pre>from astropy.io import fits\nfrom reproject import reproject_from_healpix\n\nnh_hpx = fits.open('data/NHI_HPX.fits')\nhdu = fits.open('data/A2142/mosaic_a2142.fits.gz')[0]\narray, footprint = reproject_from_healpix(nh_hpx[1], hdu.header, field='NHI')\n</pre> from astropy.io import fits from reproject import reproject_from_healpix  nh_hpx = fits.open('data/NHI_HPX.fits') hdu = fits.open('data/A2142/mosaic_a2142.fits.gz')[0] array, footprint = reproject_from_healpix(nh_hpx[1], hdu.header, field='NHI') <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> <p>We now can plot and compare the reprojected map to the cluster mosaic. Note that the projection here is smoothed and interpolated, one could use the \"true\" pixels and no smoothing by changing arguments in <code>reproject_from_healpix</code>.</p> In\u00a0[3]: Copied! <pre>import numpy as np\nimport cmasher as cmr\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\n\nplt.figure(figsize=(15,7))\n\nax1 = plt.subplot(1,2,1, projection=cluster.wcs)\nmappable = ax1.imshow(np.where(cluster.exp&gt;0, array, np.nan), origin='lower', cmap=cmr.amber)\nplt.title('$N_H$ map')\nplt.colorbar(mappable =mappable)\n\nax2 = plt.subplot(1,2,2, projection=cluster.wcs)\nmappable = ax2.imshow(np.where(cluster.exp&gt;0, cluster.img, np.nan), origin='lower', norm=LogNorm(), cmap=cmr.cosmic)\nplt.title('Counts')\nplt.colorbar(mappable =mappable)\n\nplt.show()\n</pre> import numpy as np import cmasher as cmr import matplotlib.pyplot as plt from matplotlib.colors import LogNorm  plt.figure(figsize=(15,7))  ax1 = plt.subplot(1,2,1, projection=cluster.wcs) mappable = ax1.imshow(np.where(cluster.exp&gt;0, array, np.nan), origin='lower', cmap=cmr.amber) plt.title('$N_H$ map') plt.colorbar(mappable =mappable)  ax2 = plt.subplot(1,2,2, projection=cluster.wcs) mappable = ax2.imshow(np.where(cluster.exp&gt;0, cluster.img, np.nan), origin='lower', norm=LogNorm(), cmap=cmr.cosmic) plt.title('Counts') plt.colorbar(mappable =mappable)  plt.show()"},{"location":"examples/compute_nh/#n_h-computation","title":"$N_H$ computation\u00b6","text":"<p>This tutorial aims at computing the column density for a given image using the HI4PI survey. The first cell is a mandatory data loading.</p>"},{"location":"examples/mean_model/","title":"SB model fitting","text":"In\u00a0[1]: Copied! <pre>import numpyro\n\nnumpyro.enable_x64()\nnumpyro.set_host_device_count(4)\n</pre> import numpyro  numpyro.enable_x64() numpyro.set_host_device_count(4) In\u00a0[2]: Copied! <pre>import astropy.units as u\nfrom xsb_fluc.data.cluster import Cluster\n\ncluster = Cluster(\n    imglink='data/A2142/mosaic_a2142.fits.gz',\n    explink='data/A2142/mosaic_a2142_expo.fits.gz',\n    bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',\n    reglink='data/A2142/src_ps.reg',\n    nhlink='data/A2142/A2142_nh.fits',\n    ra=239.58615,\n    dec=27.229433,\n    r_500=1.403*u.Mpc, \n    redshift=0.09,\n)\n</pre> import astropy.units as u from xsb_fluc.data.cluster import Cluster  cluster = Cluster(     imglink='data/A2142/mosaic_a2142.fits.gz',     explink='data/A2142/mosaic_a2142_expo.fits.gz',     bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',     reglink='data/A2142/src_ps.reg',     nhlink='data/A2142/A2142_nh.fits',     ra=239.58615,     dec=27.229433,     r_500=1.403*u.Mpc,      redshift=0.09, ) <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> In\u00a0[3]: Copied! <pre>import haiku as hk\nfrom xsb_fluc.simulation.mock_image import MockXrayCountsBetaModel\n\ncluster_voronoi = cluster.voronoi('data/A2142/voronoi.txt')\nimages_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster_voronoi)()))\n</pre> import haiku as hk from xsb_fluc.simulation.mock_image import MockXrayCountsBetaModel  cluster_voronoi = cluster.voronoi('data/A2142/voronoi.txt') images_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster_voronoi)())) <p>Once transformed, we can see the required parameters by using the <code>.init</code> method. Here we display them to get an idea of the shape that is accepted by <code>haiku</code> for the parameters</p> In\u00a0[4]: Copied! <pre>images_simulator.init(None)\n</pre> images_simulator.init(None) Out[4]: <pre>{'mock_xray_counts_beta_model/~/ellipse_radius': {'angle': Array(0., dtype=float32),\n  'eccentricity': Array(0., dtype=float32),\n  'x_c': Array(0., dtype=float32),\n  'y_c': Array(0., dtype=float32)},\n 'mock_xray_counts_beta_model/~/xray_surface_brightness_beta_model': {'log_bkg': Array(-5., dtype=float32),\n  'log_e_0': Array(-4., dtype=float32),\n  'log_r_c': Array(-1., dtype=float32),\n  'beta': Array(0.6666667, dtype=float32)}}</pre> In\u00a0[5]: Copied! <pre>import numpyro\nimport numpyro.distributions as dist\nimport jax.numpy as jnp \n\nprior_distributions = {\n    'mock_xray_counts_beta_model/~/ellipse_radius': {\n        'angle': dist.Uniform(0., jnp.pi/2),\n        'eccentricity': dist.Uniform(0, 0.99),\n        'x_c': dist.Normal(0, 1),\n        'y_c': dist.Normal(0, 1)\n    },\n    'mock_xray_counts_beta_model/~/xray_surface_brightness_beta_model': {\n        'log_bkg': jnp.asarray(-100.),\n        'log_e_0': dist.Uniform(-6, 0),\n        'log_r_c': dist.Uniform(-3, 0),\n        'beta': dist.Uniform(0, 5)\n    }\n}\n\ndef numpyro_model(observed_cluster=None):\n    \n    # Here, we inform numpyro that we want to draw the parameters from prior distributions\n    samples = hk.data_structures.to_haiku_dict(prior_distributions)\n    \n    for module, parameter, prior in hk.data_structures.traverse(prior_distributions):\n        \n        samples[module][parameter] = numpyro.sample(parameter, prior) if isinstance(prior, dist.Distribution) else prior\n    \n    # We compute the expected values using the samples from prior distribution\n    images_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(observed_cluster)()))\n    expected_counts = images_simulator.apply(samples)\n    \n    # We compare it to the actually observed counts in each pixel\n    numpyro.sample('likelihood', dist.Poisson(expected_counts), obs=observed_cluster.img)\n</pre> import numpyro import numpyro.distributions as dist import jax.numpy as jnp   prior_distributions = {     'mock_xray_counts_beta_model/~/ellipse_radius': {         'angle': dist.Uniform(0., jnp.pi/2),         'eccentricity': dist.Uniform(0, 0.99),         'x_c': dist.Normal(0, 1),         'y_c': dist.Normal(0, 1)     },     'mock_xray_counts_beta_model/~/xray_surface_brightness_beta_model': {         'log_bkg': jnp.asarray(-100.),         'log_e_0': dist.Uniform(-6, 0),         'log_r_c': dist.Uniform(-3, 0),         'beta': dist.Uniform(0, 5)     } }  def numpyro_model(observed_cluster=None):          # Here, we inform numpyro that we want to draw the parameters from prior distributions     samples = hk.data_structures.to_haiku_dict(prior_distributions)          for module, parameter, prior in hk.data_structures.traverse(prior_distributions):                  samples[module][parameter] = numpyro.sample(parameter, prior) if isinstance(prior, dist.Distribution) else prior          # We compute the expected values using the samples from prior distribution     images_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(observed_cluster)()))     expected_counts = images_simulator.apply(samples)          # We compare it to the actually observed counts in each pixel     numpyro.sample('likelihood', dist.Poisson(expected_counts), obs=observed_cluster.img) In\u00a0[6]: Copied! <pre>from jax.random import PRNGKey\nfrom numpyro.infer import MCMC, NUTS\n\nkernel = NUTS(numpyro_model, max_tree_depth=10)\nmcmc = MCMC(kernel, num_chains=4, num_warmup=10000, num_samples=1000)\n\nmcmc.run(PRNGKey(0), observed_cluster=cluster_voronoi)\n</pre> from jax.random import PRNGKey from numpyro.infer import MCMC, NUTS  kernel = NUTS(numpyro_model, max_tree_depth=10) mcmc = MCMC(kernel, num_chains=4, num_warmup=10000, num_samples=1000)  mcmc.run(PRNGKey(0), observed_cluster=cluster_voronoi) <pre>  0%|          | 0/11000 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/11000 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/11000 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/11000 [00:00&lt;?, ?it/s]</pre> In\u00a0[7]: Copied! <pre>import arviz as az \nimport matplotlib.pyplot as plt \n\ninference_data = az.from_numpyro(mcmc)\naz.summary(inference_data)\n</pre> import arviz as az  import matplotlib.pyplot as plt   inference_data = az.from_numpyro(mcmc) az.summary(inference_data) Out[7]: mean sd hdi_3% hdi_97% mcse_mean mcse_sd ess_bulk ess_tail r_hat angle 0.852 0.003 0.847 0.857 0.0 0.0 2749.0 2182.0 1.0 beta 0.547 0.001 0.546 0.548 0.0 0.0 1485.0 1687.0 1.0 eccentricity 0.753 0.001 0.751 0.756 0.0 0.0 3020.0 2657.0 1.0 log_e_0 -4.924 0.002 -4.927 -4.920 0.0 0.0 2066.0 2317.0 1.0 log_r_c -1.157 0.002 -1.161 -1.153 0.0 0.0 1386.0 1480.0 1.0 x_c 0.008 0.000 0.008 0.009 0.0 0.0 4577.0 2895.0 1.0 y_c 0.013 0.000 0.012 0.013 0.0 0.0 4514.0 3075.0 1.0 <p>The below cell shows a trace plot which shows convergence over time, which is clearly achieved here with the uncorrelated samples and the agreeing marginal distributions.</p> In\u00a0[8]: Copied! <pre>with az.style.context(\"arviz-darkgrid\", after_reset=True):\n    az.plot_trace(inference_data, compact=False)\n\nplt.show();\n</pre> with az.style.context(\"arviz-darkgrid\", after_reset=True):     az.plot_trace(inference_data, compact=False)  plt.show(); <p>We can also investigate the correlation of the posterior samples, which is the best view we can get of our posterior distributions. This is often referred as a pair plot or a corner plot. One should take a look at ChainConsumer to get pretty corner plot which are paper ready.</p> In\u00a0[9]: Copied! <pre>with az.style.context(\"arviz-darkgrid\", after_reset=True):\n    az.plot_pair(inference_data, kind='kde')\n\nplt.show();\n</pre> with az.style.context(\"arviz-darkgrid\", after_reset=True):     az.plot_pair(inference_data, kind='kde')  plt.show(); <pre>/Users/sdupourque/opt/anaconda3/envs/clusterLegacy/lib/python3.10/site-packages/arviz/plots/pairplot.py:232: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n  gridsize = int(dataset.dims[\"draw\"] ** 0.35)\n</pre> In\u00a0[10]: Copied! <pre>import json\nimport numpy as np\nfrom jax.tree_util import tree_map\n\n# Just save the sample for later uses\nwith open('data/A2142/posterior_parameters.json', 'w') as file:\n    json.dump(tree_map(lambda x: list(np.asarray(x)), mcmc.get_samples()), file)\n\nposterior_parameters = tree_map(lambda x: jnp.median(x), mcmc.get_samples())\n\nhk_posterior_parameters = hk.data_structures.to_haiku_dict(prior_distributions)\n\nfor module, parameter, prior in hk.data_structures.traverse(prior_distributions):\n    \n    if parameter in list(posterior_parameters.keys()):\n        hk_posterior_parameters[module][parameter] = posterior_parameters[parameter]\n        \nhk_posterior_parameters\n</pre> import json import numpy as np from jax.tree_util import tree_map  # Just save the sample for later uses with open('data/A2142/posterior_parameters.json', 'w') as file:     json.dump(tree_map(lambda x: list(np.asarray(x)), mcmc.get_samples()), file)  posterior_parameters = tree_map(lambda x: jnp.median(x), mcmc.get_samples())  hk_posterior_parameters = hk.data_structures.to_haiku_dict(prior_distributions)  for module, parameter, prior in hk.data_structures.traverse(prior_distributions):          if parameter in list(posterior_parameters.keys()):         hk_posterior_parameters[module][parameter] = posterior_parameters[parameter]          hk_posterior_parameters Out[10]: <pre>{'mock_xray_counts_beta_model/~/ellipse_radius': {'angle': Array(0.85220802, dtype=float64),\n  'eccentricity': Array(0.75334761, dtype=float64),\n  'x_c': Array(0.00841448, dtype=float64),\n  'y_c': Array(0.01253357, dtype=float64)},\n 'mock_xray_counts_beta_model/~/xray_surface_brightness_beta_model': {'log_bkg': Array(-100., dtype=float64, weak_type=True),\n  'log_e_0': Array(-4.92391862, dtype=float64),\n  'log_r_c': Array(-1.15687444, dtype=float64),\n  'beta': Array(0.54693521, dtype=float64)}}</pre> <p>Once the parameter are properly formatted, we can recreate a new simulator function which is suited to the visualization we want (as a reminder, we perform the fit on the Voronoi tesselation, so it would be ugly to plot). The next cell show how to do this.</p> In\u00a0[11]: Copied! <pre>import cmasher as cmr\nimport numpy as np\nfrom matplotlib.colors import LogNorm, SymLogNorm\n\ncluster_to_plot = cluster.reduce_to_r500(0.75)\n\nimages_simulator_full = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster_to_plot)()))\nbest_fit_image = images_simulator_full.apply(hk_posterior_parameters)\n</pre> import cmasher as cmr import numpy as np from matplotlib.colors import LogNorm, SymLogNorm  cluster_to_plot = cluster.reduce_to_r500(0.75)  images_simulator_full = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster_to_plot)())) best_fit_image = images_simulator_full.apply(hk_posterior_parameters) <p>Finally, we can plot our true image, best fit model, and fluctuation map.</p> In\u00a0[12]: Copied! <pre>fig, axs = plt.subplots(\n    figsize=(12, 5),\n    nrows=1,\n    ncols=3,\n    subplot_kw={'projection': cluster.wcs}\n)\n\nmask = cluster_to_plot.exp &gt; 0\nxsb_fluc = (cluster_to_plot.img - best_fit_image)/(2*cluster_to_plot.exp)\nimg_norm = LogNorm(vmin=0.5, vmax=200)\n\nmap_img = axs[0].imshow(np.where(mask, cluster_to_plot.img, np.nan), norm=img_norm, cmap=cmr.cosmic)\nmap_fit = axs[1].imshow(np.where(mask, best_fit_image, np.nan), norm=img_norm, cmap=cmr.cosmic)\nmap_fluc = axs[2].imshow(np.where(mask, xsb_fluc, np.nan), cmr.guppy, norm=SymLogNorm(vmin=-5e-6, vmax=5e-6, linthresh=1e-7))\n\nplt.colorbar(map_img, ax=axs[0], location='bottom', label='Counts (True image)')\nplt.colorbar(map_fit, ax=axs[1], location='bottom', label='Counts (Fitted image)')\nplt.colorbar(map_fluc, ax=axs[2], location='bottom', label='Fluctuations')\n\nplt.show();\n</pre> fig, axs = plt.subplots(     figsize=(12, 5),     nrows=1,     ncols=3,     subplot_kw={'projection': cluster.wcs} )  mask = cluster_to_plot.exp &gt; 0 xsb_fluc = (cluster_to_plot.img - best_fit_image)/(2*cluster_to_plot.exp) img_norm = LogNorm(vmin=0.5, vmax=200)  map_img = axs[0].imshow(np.where(mask, cluster_to_plot.img, np.nan), norm=img_norm, cmap=cmr.cosmic) map_fit = axs[1].imshow(np.where(mask, best_fit_image, np.nan), norm=img_norm, cmap=cmr.cosmic) map_fluc = axs[2].imshow(np.where(mask, xsb_fluc, np.nan), cmr.guppy, norm=SymLogNorm(vmin=-5e-6, vmax=5e-6, linthresh=1e-7))  plt.colorbar(map_img, ax=axs[0], location='bottom', label='Counts (True image)') plt.colorbar(map_fit, ax=axs[1], location='bottom', label='Counts (Fitted image)') plt.colorbar(map_fluc, ax=axs[2], location='bottom', label='Fluctuations')  plt.show();"},{"location":"examples/mean_model/#sb-model-fitting","title":"SB model fitting\u00b6","text":"<p>In this notebook, I show how to use <code>numpyro</code> &amp; <code>haiku</code> to perform a MCMC fitting on the surface brightness of a cluster.</p>"},{"location":"examples/mean_model/#build-the-numpyro-model","title":"Build the <code>numpyro</code> model\u00b6","text":"<p>I'll demonstrate how to fit an elliptic model for the surface brightness, using MCMC sample with both <code>haiku</code> to define the model and its parameters and <code>numpyro</code>to perform the sampling using the NUTS sampler. In the following cell, I reduce the <code>cluster</code> using the Voronoi tesselation derived in the associated notebook, and will infer the number of counts in each of the bins. The <code>MockXrayCountsBetaModel</code> is a built-in of the <code>xsb_fluc</code> package and is programmed as an haiku Module, so it has to be transformed.</p>"},{"location":"examples/mean_model/#run-the-mcmc","title":"Run the MCMC\u00b6","text":"<p>Now that the model is built, we can leverage numpyro to perform an efficient sampling. The NUTS sampler is an adaptive sampler that excels at generating uncorrelated parameters really fast. By this, I mean that it requires a reduced number of steps to converge and produce quality posterior samples. In the following cell, I build a NUTS kernel and run 4 chains in parallel with 10 000 burn-in steps.</p>"},{"location":"examples/mean_model/#analyse-the-result","title":"Analyse the result\u00b6","text":"<p>Now that the MCMC is run, we can check the convergence and analyse the results using <code>arviz</code> (imo the best library to analyses MCMC results). We can build an <code>InferenceData</code> object from our previous MCMC and check some summary statistics. I would like to focus on the $\\hat{R}$ parameter which is a good criterion to asses the convergence of a chain, supposedly achieved if $\\hat{R} &lt; 1.01$. This is true for every parameters of our model.</p>"},{"location":"examples/mean_model/#posterior-predictive","title":"Posterior predictive\u00b6","text":"<p>With these posterior samples, we can have a nice idea of what is the best image we can get and even compute fluctuation maps ! To do so, we just need to inject the parameters in our previously define model. In general, the median of the distribution is coincident with the best fit parameters so we use it to plot our posterior predictive and fluctuation map. The cell below is just a parameterization to build a haiku-friendly dictionary of parameters.</p>"},{"location":"examples/mock_fluctuations/","title":"Mock fluctuations","text":"In\u00a0[\u00a0]: Copied!"},{"location":"examples/open_data/","title":"Load data","text":"<p>In this notebook, I'll show how to load cluster data using the XCOP-standard reduced data. This means data are reduced in the 0.7-1.2 keV band with a procedure detailed in Ghirardini &amp; al. 2019 and Ettori &amp; al. 2019. This is done using the <code>Cluster</code> class. First, we must define the path to the data.</p> In\u00a0[1]: Copied! <pre>import astropy.units as u\nfrom xsb_fluc.data.cluster import Cluster\n\ncluster = Cluster(\n    imglink='data/A2142/mosaic_a2142.fits.gz',\n    explink='data/A2142/mosaic_a2142_expo.fits.gz',\n    bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',\n    reglink='data/A2142/src_ps.reg',\n    nhlink='data/A2142/A2142_nh.fits',\n    ra=239.58615,\n    dec=27.229433,\n    r_500=1.403*u.Mpc, \n    redshift=0.09,\n)\n</pre> import astropy.units as u from xsb_fluc.data.cluster import Cluster  cluster = Cluster(     imglink='data/A2142/mosaic_a2142.fits.gz',     explink='data/A2142/mosaic_a2142_expo.fits.gz',     bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',     reglink='data/A2142/src_ps.reg',     nhlink='data/A2142/A2142_nh.fits',     ra=239.58615,     dec=27.229433,     r_500=1.403*u.Mpc,      redshift=0.09, ) <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> <p>Let's plot it !</p> In\u00a0[2]: Copied! <pre>cluster.plot_cluster()\n</pre> cluster.plot_cluster() <p>I implemented convenience functions to reduce the size of the images to a given fraction of $R_{500}$ using only the center and size supplied when creating the <code>Cluster</code>.</p> In\u00a0[3]: Copied! <pre>cluster.reduce_to_r500(r500_cut=1).plot_cluster()\n</pre> cluster.reduce_to_r500(r500_cut=1).plot_cluster() <p>There are also convenience functions to rebin with a given factor. It can be chained with other functions on clusters. Here I rebin with a factor of 8 so that each new pixel is defined with a square of 8 smaller pixels.</p> In\u00a0[4]: Copied! <pre>cluster.reduce_to_r500(r500_cut=1).rebin(8).plot_cluster()\n</pre> cluster.reduce_to_r500(r500_cut=1).rebin(8).plot_cluster()"},{"location":"examples/power_spectrum/","title":"Computing the power spectrum","text":"In\u00a0[1]: Copied! <pre>import astropy.units as u\n\nfrom xsb_fluc.data.cluster import Cluster\n\ncluster = Cluster(\n    imglink='data/A2142/mosaic_a2142.fits.gz',\n    explink='data/A2142/mosaic_a2142_expo.fits.gz',\n    bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',\n    reglink='data/A2142/src_ps.reg',\n    nhlink='data/A2142/A2142_nh.fits',\n    ra=239.58615,\n    dec=27.229433,\n    r_500=1.403*u.Mpc, \n    redshift=0.09,\n)\n\ncluster = cluster.reduce_to_r500(1).rebin(5)\ncluster.plot_cluster()\n</pre> import astropy.units as u  from xsb_fluc.data.cluster import Cluster  cluster = Cluster(     imglink='data/A2142/mosaic_a2142.fits.gz',     explink='data/A2142/mosaic_a2142_expo.fits.gz',     bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',     reglink='data/A2142/src_ps.reg',     nhlink='data/A2142/A2142_nh.fits',     ra=239.58615,     dec=27.229433,     r_500=1.403*u.Mpc,      redshift=0.09, )  cluster = cluster.reduce_to_r500(1).rebin(5) cluster.plot_cluster() <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> <p>In this cell, I load the previously determined best-fit parameters from the MCMC notebook. There is also a bit of formatting to extract the Maximum A Posteriori and build an appropriate dictionary that can be fed to <code>haiku</code> functions.</p> In\u00a0[2]: Copied! <pre>import haiku as hk\nimport json\nimport jax.numpy as jnp\nfrom jax.tree_util import tree_map\nfrom xsb_fluc.simulation.mock_image import MockXrayCountsBetaModel\n\n# This is the function we used to fit the X-ray surface brightness model\nimages_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster)()))\n\n# We reload the parameters and parse them to the appropriate format\nwith open('data/A2142/posterior_parameters.json', 'r') as file:\n    posterior_parameters = {key:jnp.asarray(value) for key, value in json.load(file).items()}\n    # I have to manually set the background here because json encoding is buggy \n    posterior_parameters['log_bkg'] = jnp.asarray(-50.)\n\n# We compute the median of the posterior samples, which is coincident with the \n# MAP estimate when the posterior distributions are constrained\nposterior_median = tree_map(lambda x: jnp.median(x), posterior_parameters)\n\n# Here we change the structure of the dictionary so it is compliant with haiku\nhk_posterior_median = hk.data_structures.to_haiku_dict(images_simulator.init(None))\n\nfor module, parameter, prior in hk.data_structures.traverse(hk_posterior_median):\n    \n    if parameter in list(posterior_parameters.keys()):\n        hk_posterior_median[module][parameter] = posterior_median[parameter]\n        \nposterior_image = images_simulator.apply(hk_posterior_median)\n</pre> import haiku as hk import json import jax.numpy as jnp from jax.tree_util import tree_map from xsb_fluc.simulation.mock_image import MockXrayCountsBetaModel  # This is the function we used to fit the X-ray surface brightness model images_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster)()))  # We reload the parameters and parse them to the appropriate format with open('data/A2142/posterior_parameters.json', 'r') as file:     posterior_parameters = {key:jnp.asarray(value) for key, value in json.load(file).items()}     # I have to manually set the background here because json encoding is buggy      posterior_parameters['log_bkg'] = jnp.asarray(-50.)  # We compute the median of the posterior samples, which is coincident with the  # MAP estimate when the posterior distributions are constrained posterior_median = tree_map(lambda x: jnp.median(x), posterior_parameters)  # Here we change the structure of the dictionary so it is compliant with haiku hk_posterior_median = hk.data_structures.to_haiku_dict(images_simulator.init(None))  for module, parameter, prior in hk.data_structures.traverse(hk_posterior_median):          if parameter in list(posterior_parameters.keys()):         hk_posterior_median[module][parameter] = posterior_median[parameter]          posterior_image = images_simulator.apply(hk_posterior_median) <p>Using these best-fit parameters, we can compute a single fluctuation map as done before, and the associated mask which is a combination between the excluded regions, the CCD gaps and the $R_{500}$ region.</p> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt \nimport cmasher as cmr \nfrom matplotlib.colors import SymLogNorm\n\nmask = (cluster.exp&gt;0) &amp; (cluster.center.separation(cluster.coords) &lt; cluster.t_500)\nfluc = jnp.nan_to_num((cluster.img - posterior_image)/(2*cluster.exp))\n\nfig, axs = plt.subplots(nrows=1, ncols=2, subplot_kw={'projection':cluster.wcs})\nmap_fluc = axs[0].imshow(jnp.where(mask, fluc, jnp.nan), norm=SymLogNorm(vmin=-5e-6, vmax=5e-6, linthresh=1e-7), cmap=cmr.guppy)\nmap_mask = axs[1].imshow(mask)\n\nplt.colorbar(map_fluc, ax=axs[0], location='bottom', label='Fluctuations')\nplt.colorbar(map_mask, ax=axs[1], location='bottom', label='Mask');\n</pre> import matplotlib.pyplot as plt  import cmasher as cmr  from matplotlib.colors import SymLogNorm  mask = (cluster.exp&gt;0) &amp; (cluster.center.separation(cluster.coords) &lt; cluster.t_500) fluc = jnp.nan_to_num((cluster.img - posterior_image)/(2*cluster.exp))  fig, axs = plt.subplots(nrows=1, ncols=2, subplot_kw={'projection':cluster.wcs}) map_fluc = axs[0].imshow(jnp.where(mask, fluc, jnp.nan), norm=SymLogNorm(vmin=-5e-6, vmax=5e-6, linthresh=1e-7), cmap=cmr.guppy) map_mask = axs[1].imshow(mask)  plt.colorbar(map_fluc, ax=axs[0], location='bottom', label='Fluctuations') plt.colorbar(map_mask, ax=axs[1], location='bottom', label='Mask'); <p>With this mask and image, we can define some scales of interest (in units of $R_{500}$) and compute the associated power spectrum using the Mexican-Hat filtering implemented in this package. This method is bound to the <code>PowerSpectrum</code> operator. Below I show the power spectrum associated to the absolute fluctuation map of A2142.</p> In\u00a0[4]: Copied! <pre>import jax.numpy as jnp\nimport haiku as hk\nfrom xsb_fluc.simulation.power_spectrum import PowerSpectrum\n\nscales = jnp.geomspace(0.05, 1, 20)\n\n# Note that you can also fix the scales in the lambda function\npower_spectrum = hk.without_apply_rng(\n    hk.transform(\n        lambda img, s: PowerSpectrum(cluster, mask=mask)(img, s)\n    )\n)\n\nps_fluc = power_spectrum.apply(None, fluc, scales)\n\nplt.plot(scales, ps_fluc)\nplt.xlabel('Scales [$R_{500}$]')\nplt.ylabel('Power spectrum')\nplt.loglog();\n</pre> import jax.numpy as jnp import haiku as hk from xsb_fluc.simulation.power_spectrum import PowerSpectrum  scales = jnp.geomspace(0.05, 1, 20)  # Note that you can also fix the scales in the lambda function power_spectrum = hk.without_apply_rng(     hk.transform(         lambda img, s: PowerSpectrum(cluster, mask=mask)(img, s)     ) )  ps_fluc = power_spectrum.apply(None, fluc, scales)  plt.plot(scales, ps_fluc) plt.xlabel('Scales [$R_{500}$]') plt.ylabel('Power spectrum') plt.loglog(); <p>Note that this mask can be used to compute power spectra in various regions of the fluctuation map. In the following cell, I compute the power spectrum in 4 concentric annuli.</p> In\u00a0[5]: Copied! <pre>import jax.numpy as jnp\nimport haiku as hk\nimport cmasher as cmr \nfrom xsb_fluc.simulation.power_spectrum import PowerSpectrum\n\nscales = jnp.geomspace(0.05, 1, 20)\n# Separation from the Planck center in units of R500\ndistance = jnp.asarray((cluster.center.separation(cluster.coords)/cluster.t_500).to(u.dimensionless_unscaled))\n\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n\nmask_img = jnp.ones_like(distance)*jnp.nan\n\nfor low_rad, high_rad in [(0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1.)]:\n\n    # Note that you can also fix the scales in the lambda function\n    local_mask = (low_rad &lt;= distance) &amp; (distance&lt; high_rad) &amp; mask\n    mask_img = mask_img.at[local_mask].set(high_rad) \n    \n    power_spectrum = hk.without_apply_rng(\n        hk.transform(\n            lambda img, s: PowerSpectrum(cluster, mask=local_mask)(img, s)\n        )\n    )\n\n    ps_fluc = power_spectrum.apply(None, fluc, scales)\n    \n    axs[0].plot(scales, ps_fluc, color=cmr.amber_r(high_rad))\n\naxs[0].loglog()\naxs[0].set_xlabel('Scales [$R_{500}$]')\naxs[0].set_ylabel('Power spectrum')\naxs[1].imshow(mask_img, cmap=cmr.ember_r)\naxs[1].set_axis_off()\nplt.show();\n</pre> import jax.numpy as jnp import haiku as hk import cmasher as cmr  from xsb_fluc.simulation.power_spectrum import PowerSpectrum  scales = jnp.geomspace(0.05, 1, 20) # Separation from the Planck center in units of R500 distance = jnp.asarray((cluster.center.separation(cluster.coords)/cluster.t_500).to(u.dimensionless_unscaled))  fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))  mask_img = jnp.ones_like(distance)*jnp.nan  for low_rad, high_rad in [(0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1.)]:      # Note that you can also fix the scales in the lambda function     local_mask = (low_rad &lt;= distance) &amp; (distance&lt; high_rad) &amp; mask     mask_img = mask_img.at[local_mask].set(high_rad)           power_spectrum = hk.without_apply_rng(         hk.transform(             lambda img, s: PowerSpectrum(cluster, mask=local_mask)(img, s)         )     )      ps_fluc = power_spectrum.apply(None, fluc, scales)          axs[0].plot(scales, ps_fluc, color=cmr.amber_r(high_rad))  axs[0].loglog() axs[0].set_xlabel('Scales [$R_{500}$]') axs[0].set_ylabel('Power spectrum') axs[1].imshow(mask_img, cmap=cmr.ember_r) axs[1].set_axis_off() plt.show();"},{"location":"examples/power_spectrum/#computing-the-power-spectrum","title":"Computing the power spectrum\u00b6","text":"<p>In this notebook, I will show how to use the Mexican-hat filtering from Ar\u00e9valo &amp; al. to compute the power spectra of images with arbitrary masks such as excluded point sources. The cell below is the mandatory data loading.</p>"},{"location":"examples/sbi_with_spectra/","title":"Simulate spectra","text":"In\u00a0[8]: Copied! <pre>import astropy.units as u\nfrom xsb_fluc.data.cluster import Cluster\n\ncluster = Cluster(\n    imglink='data/A2142/mosaic_a2142.fits.gz',\n    explink='data/A2142/mosaic_a2142_expo.fits.gz',\n    bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',\n    reglink='data/A2142/src_ps.reg',\n    nhlink='data/A2142/A2142_nh.fits',\n    ra=239.58615,\n    dec=27.229433,\n    r_500=1.403*u.Mpc, \n    redshift=0.09,\n)\n\ncluster = cluster.reduce_to_r500(1).rebin(5)\ncluster.plot_cluster()\n</pre> import astropy.units as u from xsb_fluc.data.cluster import Cluster  cluster = Cluster(     imglink='data/A2142/mosaic_a2142.fits.gz',     explink='data/A2142/mosaic_a2142_expo.fits.gz',     bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',     reglink='data/A2142/src_ps.reg',     nhlink='data/A2142/A2142_nh.fits',     ra=239.58615,     dec=27.229433,     r_500=1.403*u.Mpc,      redshift=0.09, )  cluster = cluster.reduce_to_r500(1).rebin(5) cluster.plot_cluster() <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> In\u00a0[9]: Copied! <pre>import json \nimport haiku as hk\nimport jax.numpy as jnp\nfrom xsb_fluc.simulation.mock_image import MockXrayCountsBetaModel\n\n# We reload the parameters and parse them to the appropriate format\nwith open('data/A2142/posterior_parameters.json', 'r') as file:\n    posterior_parameters = {key:jnp.asarray(value) for key, value in json.load(file).items()}\n\nimages_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster)()))\n</pre> import json  import haiku as hk import jax.numpy as jnp from xsb_fluc.simulation.mock_image import MockXrayCountsBetaModel  # We reload the parameters and parse them to the appropriate format with open('data/A2142/posterior_parameters.json', 'r') as file:     posterior_parameters = {key:jnp.asarray(value) for key, value in json.load(file).items()}  images_simulator = hk.without_apply_rng(hk.transform(lambda : MockXrayCountsBetaModel(cluster)())) In\u00a0[11]: Copied! <pre>class SpectraSimulator(hk.Module):\n    \n    pass\n</pre> class SpectraSimulator(hk.Module):          pass In\u00a0[12]: Copied! <pre>import os\nimport numpy as np\nimport sys\nimport jax\nimport haiku as hk\nfrom xsb_fluc.data.mean_model import MeanModel\n\nfrom xsb_fluc.utils.mock_image import ImageGenerator\nfrom xsb_fluc.data.power_spectrum import PowerSpectrum\nfrom xsb_fluc.utils.config import config\nfrom xsb_fluc.utils.misc import rng_key\nfrom xsb_fluc.utils.ps import chexmate_low_scale\nimport jax.numpy as jnp\nfrom jax import config as jax_config\n\njax_config.update(\"jax_enable_x64\", True)\n\n\n\n\nmean_model = MeanModel.from_data(data)\nreduced_data = data.reduce_fov(mean_model, aperture)\nreduced_mean_model = MeanModel.from_data(reduced_data)\n\nmask_list = [(reduced_data.exp &gt; 0.) &amp; (reduced_mean_model.rad &lt; 1.)]\nscales_list = [jnp.geomspace(chexmate_low_scale(cluster.z), 1., 20)]\nps_func_list = [jax.pmap(lambda i: hk.without_apply_rng(\n    hk.transform(lambda img: PowerSpectrum(reduced_data, mask=mask_list[0])(img, scales_list[0]))).apply(None, i))]\n\ngen = ImageGenerator(reduced_data, reduced_mean_model)\nbkg = jnp.asarray(reduced_data.bkg[None, ...])\nexp = jnp.asarray(reduced_data.exp[None, ...])\nC = jnp.ones_like(exp) * 10 ** float(reduced_mean_model.posterior_median['log_bkg'])\n#Reference simulations here\n\nx_regions = [[] for region in regions]\nx_regions_rel = [[] for region in regions_rel]\ntheta = []\n\nfor _ in range(1000):\n\n    log_sigma = -0.5 * jnp.ones((1,))\n    log_inj = -1.3 * jnp.ones((1,))\n    alpha = 11 / 3 * jnp.ones((1,))\n\n    theta.append(jnp.hstack([log_sigma, log_inj, alpha]))\n\n    counts_perturbed, counts_rest, pars_val = gen(log_sigma, log_inj, alpha)\n\n    null = jax.random.poisson(rng_key(), counts_rest)\n    img_list_abs = jnp.nan_to_num((counts_perturbed - counts_rest) / (2 * exp)) * (exp &gt; 0.)\n    img_list_abs_null = jnp.nan_to_num((null - counts_rest) / (2 * exp)) * (exp &gt; 0.)\n\n    img_list_rel = jnp.nan_to_num(((counts_perturbed - bkg) / exp - C) / ((counts_rest - bkg) / exp - C)) * (exp &gt; 0.)\n    img_list_rel_null = jnp.nan_to_num(((null - bkg) / exp - C) / ((counts_rest - bkg) / exp - C)) * (exp &gt; 0.)\n\n    for x_reg, ps in zip(x_regions, ps_func_list):\n        x_reg.append(jnp.log(ps(img_list_abs)) - jnp.log(ps(img_list_abs_null)))\n\n    for x_reg, ps in zip(x_regions_rel, ps_func_list):\n        x_reg.append(jnp.log(ps(img_list_rel)) - jnp.log(ps(img_list_rel_null)))\n\nnp.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/ref/theta.txt'), np.stack(theta))\n\nfor x_reg, region in zip(x_regions, regions):\n    np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/ref/x_{region}.txt'), np.vstack(x_reg))\n\nfor x_reg, region in zip(x_regions_rel, regions_rel):\n    np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/ref/x_{region}.txt'), np.vstack(x_reg))\n\n#Simulations with prior here\n\nx_regions = [[] for region in regions]\ntheta = []\nfirst_key = rng_key()\n\nfor _ in range(500000):\n\n    key = jax.random.split(first_key, 5)\n    first_key = key[0]\n\n    log_sigma = jax.random.uniform(key[1], minval=-2., maxval=1., shape=(1,))\n    log_inj = jax.random.uniform(key[2], minval=-2., maxval=1., shape=(1,))\n    alpha = jax.random.uniform(key[3], minval=0., maxval=7., shape=(1,))\n\n    theta.append(jnp.hstack([log_sigma, log_inj, alpha]))\n\n    counts_perturbed, counts_rest, pars_val = gen(log_sigma, log_inj, alpha)\n\n    null = jax.random.poisson(key[4], counts_rest)\n    img_list_abs = jnp.nan_to_num((counts_perturbed - counts_rest) / (2 * exp)) * (exp &gt; 0.)\n    img_list_abs_null = jnp.nan_to_num((null - counts_rest) / (2 * exp)) * (exp &gt; 0.)\n\n    for x_reg, ps in zip(x_regions, ps_func_list):\n        x_reg.append(jnp.log(ps(img_list_abs)) - jnp.log(ps(img_list_abs_null)))\n\"\"\"\nnp.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/theta.txt'), np.stack(theta))\n\nfor x_reg, region in zip(x_regions, regions):\n    np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/x_{region}.txt'), np.vstack(x_reg))\n\"\"\"\n</pre> import os import numpy as np import sys import jax import haiku as hk from xsb_fluc.data.mean_model import MeanModel  from xsb_fluc.utils.mock_image import ImageGenerator from xsb_fluc.data.power_spectrum import PowerSpectrum from xsb_fluc.utils.config import config from xsb_fluc.utils.misc import rng_key from xsb_fluc.utils.ps import chexmate_low_scale import jax.numpy as jnp from jax import config as jax_config  jax_config.update(\"jax_enable_x64\", True)     mean_model = MeanModel.from_data(data) reduced_data = data.reduce_fov(mean_model, aperture) reduced_mean_model = MeanModel.from_data(reduced_data)  mask_list = [(reduced_data.exp &gt; 0.) &amp; (reduced_mean_model.rad &lt; 1.)] scales_list = [jnp.geomspace(chexmate_low_scale(cluster.z), 1., 20)] ps_func_list = [jax.pmap(lambda i: hk.without_apply_rng(     hk.transform(lambda img: PowerSpectrum(reduced_data, mask=mask_list[0])(img, scales_list[0]))).apply(None, i))]  gen = ImageGenerator(reduced_data, reduced_mean_model) bkg = jnp.asarray(reduced_data.bkg[None, ...]) exp = jnp.asarray(reduced_data.exp[None, ...]) C = jnp.ones_like(exp) * 10 ** float(reduced_mean_model.posterior_median['log_bkg']) #Reference simulations here  x_regions = [[] for region in regions] x_regions_rel = [[] for region in regions_rel] theta = []  for _ in range(1000):      log_sigma = -0.5 * jnp.ones((1,))     log_inj = -1.3 * jnp.ones((1,))     alpha = 11 / 3 * jnp.ones((1,))      theta.append(jnp.hstack([log_sigma, log_inj, alpha]))      counts_perturbed, counts_rest, pars_val = gen(log_sigma, log_inj, alpha)      null = jax.random.poisson(rng_key(), counts_rest)     img_list_abs = jnp.nan_to_num((counts_perturbed - counts_rest) / (2 * exp)) * (exp &gt; 0.)     img_list_abs_null = jnp.nan_to_num((null - counts_rest) / (2 * exp)) * (exp &gt; 0.)      img_list_rel = jnp.nan_to_num(((counts_perturbed - bkg) / exp - C) / ((counts_rest - bkg) / exp - C)) * (exp &gt; 0.)     img_list_rel_null = jnp.nan_to_num(((null - bkg) / exp - C) / ((counts_rest - bkg) / exp - C)) * (exp &gt; 0.)      for x_reg, ps in zip(x_regions, ps_func_list):         x_reg.append(jnp.log(ps(img_list_abs)) - jnp.log(ps(img_list_abs_null)))      for x_reg, ps in zip(x_regions_rel, ps_func_list):         x_reg.append(jnp.log(ps(img_list_rel)) - jnp.log(ps(img_list_rel_null)))  np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/ref/theta.txt'), np.stack(theta))  for x_reg, region in zip(x_regions, regions):     np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/ref/x_{region}.txt'), np.vstack(x_reg))  for x_reg, region in zip(x_regions_rel, regions_rel):     np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/ref/x_{region}.txt'), np.vstack(x_reg))  #Simulations with prior here  x_regions = [[] for region in regions] theta = [] first_key = rng_key()  for _ in range(500000):      key = jax.random.split(first_key, 5)     first_key = key[0]      log_sigma = jax.random.uniform(key[1], minval=-2., maxval=1., shape=(1,))     log_inj = jax.random.uniform(key[2], minval=-2., maxval=1., shape=(1,))     alpha = jax.random.uniform(key[3], minval=0., maxval=7., shape=(1,))      theta.append(jnp.hstack([log_sigma, log_inj, alpha]))      counts_perturbed, counts_rest, pars_val = gen(log_sigma, log_inj, alpha)      null = jax.random.poisson(key[4], counts_rest)     img_list_abs = jnp.nan_to_num((counts_perturbed - counts_rest) / (2 * exp)) * (exp &gt; 0.)     img_list_abs_null = jnp.nan_to_num((null - counts_rest) / (2 * exp)) * (exp &gt; 0.)      for x_reg, ps in zip(x_regions, ps_func_list):         x_reg.append(jnp.log(ps(img_list_abs)) - jnp.log(ps(img_list_abs_null))) \"\"\" np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/theta.txt'), np.stack(theta))  for x_reg, region in zip(x_regions, regions):     np.savetxt(os.path.join(config.RESULTS_PATH, f'mock_observables/{name}/x_{region}.txt'), np.vstack(x_reg)) \"\"\" <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[12], line 9\n      6 from xsb_fluc.data.mean_model import MeanModel\n      8 from xsb_fluc.utils.mock_image import ImageGenerator\n----&gt; 9 from xsb_fluc.data.power_spectrum import PowerSpectrum\n     10 from xsb_fluc.utils.config import config\n     11 from xsb_fluc.utils.misc import rng_key\n\nModuleNotFoundError: No module named 'xsb_fluc.data.power_spectrum'</pre>"},{"location":"examples/sbi_with_spectra/#simulate-spectra","title":"Simulate spectra\u00b6","text":""},{"location":"examples/voronoi/","title":"Voronoi tesselation","text":"In\u00a0[1]: Copied! <pre>import astropy.units as u\nfrom xsb_fluc.data.cluster import Cluster\n\ncluster = Cluster(\n    imglink='data/A2142/mosaic_a2142.fits.gz',\n    explink='data/A2142/mosaic_a2142_expo.fits.gz',\n    bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',\n    reglink='data/A2142/src_ps.reg',\n    nhlink='data/A2142/A2142_nh.fits',\n    ra=239.58615,\n    dec=27.229433,\n    r_500=1.403*u.Mpc, \n    redshift=0.09,\n)\n\ncluster = cluster.reduce_to_r500(1).rebin(5)\ncluster.plot_cluster()\n</pre> import astropy.units as u from xsb_fluc.data.cluster import Cluster  cluster = Cluster(     imglink='data/A2142/mosaic_a2142.fits.gz',     explink='data/A2142/mosaic_a2142_expo.fits.gz',     bkglink='data/A2142/mosaic_a2142_bkg.fits.gz',     reglink='data/A2142/src_ps.reg',     nhlink='data/A2142/A2142_nh.fits',     ra=239.58615,     dec=27.229433,     r_500=1.403*u.Mpc,      redshift=0.09, )  cluster = cluster.reduce_to_r500(1).rebin(5) cluster.plot_cluster() <pre>WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / Stellar reference frame \nthe RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\nWARNING: FITSFixedWarning: EQUINOX = '2000.0 ' / Coordinate system equinox \na floating-point value was expected. [astropy.wcs.wcs]\n</pre> <p>Using this cluster, we can perform a Voronoi tesselation using the implementation from the <code>vorbin</code>package, which requires a signal-to-noise function. Here, I do not target a specific SNR but rather a given number of counts (700, which is far greater then what you usually do). The <code>vorbin</code> package works with 1D inputs, so we flatten the various data from our cluster. We also filter for pixels that are too far away from the center and that are not exposed.</p> In\u00a0[2]: Copied! <pre>import numpy as np\nfrom vorbin.voronoi_2d_binning import voronoi_2d_binning\n\ndef sn_func(index, signal, noise):\n\n    return np.sum(signal[index])\n\nX,Y = np.indices(cluster.shape)\nvalid = (cluster.exp&gt;0)&amp;(cluster.coords.separation(cluster.center) &lt; cluster.t_500)\n\nx = X[valid].flatten()\ny = Y[valid].flatten()\ns = cluster.img[valid].flatten()\nn = np.ones_like(s)\n\nbin_number, xBin, yBin, xBar, yBar, sn, nPixels, scale = voronoi_2d_binning(x, y, s, n, 700, pixelsize=1, quiet = True, sn_func=sn_func, plot=False)\n\nnp.savetxt('data/A2142/voronoi.txt', bin_number)\n</pre> import numpy as np from vorbin.voronoi_2d_binning import voronoi_2d_binning  def sn_func(index, signal, noise):      return np.sum(signal[index])  X,Y = np.indices(cluster.shape) valid = (cluster.exp&gt;0)&amp;(cluster.coords.separation(cluster.center) &lt; cluster.t_500)  x = X[valid].flatten() y = Y[valid].flatten() s = cluster.img[valid].flatten() n = np.ones_like(s)  bin_number, xBin, yBin, xBar, yBar, sn, nPixels, scale = voronoi_2d_binning(x, y, s, n, 700, pixelsize=1, quiet = True, sn_func=sn_func, plot=False)  np.savetxt('data/A2142/voronoi.txt', bin_number) In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\nimport cmasher as cmr\nfrom matplotlib.colors import LogNorm\n\nindexes = (cluster.exp&gt;0)&amp;(cluster.coords.separation(cluster.center) &lt; cluster.t_500)\ny_ref, x_ref = cluster.y_ref[indexes], cluster.x_ref[indexes]\nimg = np.array(cluster.img[indexes].astype(int))\nexp = np.array(cluster.exp[indexes].astype(np.float32))\n\nvoronoi_img = np.zeros_like(cluster.img)*np.nan\nbin_number_img = np.zeros_like(cluster.img)*np.nan\nvoronoi_img_flat = voronoi_img[indexes]\nbin_number_img_flat = np.zeros_like(voronoi_img_flat)\n\nunique_bin = np.unique(bin_number)\n\nfor i, number in enumerate(unique_bin):\n    bin_index = (bin_number == number)\n    voronoi_img_flat[bin_index] = np.sum(img[bin_index])\n    bin_number_img_flat[bin_index] = number\n    \nvoronoi_img[indexes] = voronoi_img_flat\nbin_number_img[indexes] = bin_number_img_flat\n\nfig, axs = plt.subplots(\n    figsize=(12, 5),\n    nrows=1,\n    ncols=2,\n    subplot_kw={'projection': cluster.wcs}\n)\n\nimg_plot = axs[0].imshow(voronoi_img, norm=LogNorm(vmin=500), cmap=cmr.cosmic)\n\nplt.colorbar(\n    mappable=img_plot,\n    ax=axs[0],\n    location='bottom',\n    label=\"Image (Photons)\"\n)\n\nnumber_plot = axs[1].imshow(bin_number_img, cmap='tab20')\n\nplt.colorbar(\n    mappable=number_plot,\n    ax=axs[1],\n    location='bottom',\n    label=\"Bin number\"\n)\n\nplt.show();\n</pre> import matplotlib.pyplot as plt import cmasher as cmr from matplotlib.colors import LogNorm  indexes = (cluster.exp&gt;0)&amp;(cluster.coords.separation(cluster.center) &lt; cluster.t_500) y_ref, x_ref = cluster.y_ref[indexes], cluster.x_ref[indexes] img = np.array(cluster.img[indexes].astype(int)) exp = np.array(cluster.exp[indexes].astype(np.float32))  voronoi_img = np.zeros_like(cluster.img)*np.nan bin_number_img = np.zeros_like(cluster.img)*np.nan voronoi_img_flat = voronoi_img[indexes] bin_number_img_flat = np.zeros_like(voronoi_img_flat)  unique_bin = np.unique(bin_number)  for i, number in enumerate(unique_bin):     bin_index = (bin_number == number)     voronoi_img_flat[bin_index] = np.sum(img[bin_index])     bin_number_img_flat[bin_index] = number      voronoi_img[indexes] = voronoi_img_flat bin_number_img[indexes] = bin_number_img_flat  fig, axs = plt.subplots(     figsize=(12, 5),     nrows=1,     ncols=2,     subplot_kw={'projection': cluster.wcs} )  img_plot = axs[0].imshow(voronoi_img, norm=LogNorm(vmin=500), cmap=cmr.cosmic)  plt.colorbar(     mappable=img_plot,     ax=axs[0],     location='bottom',     label=\"Image (Photons)\" )  number_plot = axs[1].imshow(bin_number_img, cmap='tab20')  plt.colorbar(     mappable=number_plot,     ax=axs[1],     location='bottom',     label=\"Bin number\" )  plt.show();"},{"location":"examples/voronoi/#voronoi-tesselation","title":"Voronoi tesselation\u00b6","text":"<p>This notebook shows how to perform voronoi tesselation using the <code>vorbin</code>package. The following cell is the mandatory data loading.</p>"},{"location":"examples/voronoi/#plotting-the-results","title":"Plotting the results\u00b6","text":"<p>Here I just plot the result. In practice, the image is flattened and reduced to a 1D vector, but this script is made to unflatten it and plot the corresponding Voronoi regions.</p>"},{"location":"references/data/","title":"data","text":""},{"location":"references/data/#xsb_fluc.data.cluster","title":"<code>xsb_fluc.data.cluster</code>","text":""},{"location":"references/data/#xsb_fluc.data.cluster.Cluster","title":"<code>Cluster</code>","text":"<p>Data container for a cluster observation/mosaic as defined by pyproffit.</p> <p>Attributes:</p> Name Type Description <code>img</code> <code>ndarray</code> <p>Image data</p> <code>exp</code> <code>ndarray</code> <p>Exposure map</p> <code>bkg</code> <code>ndarray</code> <p>Background map</p> <code>nh</code> <code>ndarray</code> <p>Hydrogen column density map</p> <code>wcs</code> <code>WCS</code> <p>WCS object</p> <code>header</code> <code>Header</code> <p>Header object</p> <code>degree_per_pixel</code> <code>Quantity</code> <p>Angular size of a pixel in degrees</p> <code>kpc_per_pixel</code> <code>Quantity</code> <p>Angular size of a pixel in kpc</p> <code>shape</code> <code>tuple</code> <p>Shape of the image</p> <code>x_c</code> <code>float</code> <p>X coordinate of the cluster center</p> <code>y_c</code> <code>float</code> <p>Y coordinate of the cluster center</p> <code>y_ref</code> <code>ndarray</code> <p>Y coordinate of the image</p> <code>x_ref</code> <code>ndarray</code> <p>X coordinate of the image</p> <code>coords</code> <code>SkyCoord</code> <p>Coordinates of the image</p> <code>z</code> <code>float</code> <p>Redshift of the cluster</p> <code>r_500</code> <code>Quantity</code> <p>Radius of the cluster at 500 times the critical density.</p> <code>t_500</code> <code>Quantity</code> <p>Angular radius of the cluster at 500 times the critical density.</p> <code>center</code> <code>SkyCoord</code> <p>Coordinates of the cluster center</p> <code>name</code> <code>str</code> <p>Name of the cluster</p> <code>imglink</code> <code>str</code> <p>Path to the image file</p> <code>explink</code> <code>str</code> <p>Path to the exposure map file</p> <code>bkglink</code> <code>str</code> <p>Path to the background map file</p> <code>cosmo</code> <code>FlatLambdaCDM</code> <p>Cosmology used to compute the angular and physical sizes</p> <code>regions</code> <code>Regions</code> <p>Regions to exclude from the analysis</p> <code>unmasked_img</code> <code>ndarray</code> <p>Unmasked image data</p> <code>unmasked_exposure</code> <code>ndarray</code> <p>Unmasked exposure map</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>class Cluster:\n    \"\"\"\n    Data container for a cluster observation/mosaic as defined by pyproffit.\n\n    Attributes:\n        img (np.ndarray): Image data\n        exp (np.ndarray): Exposure map\n        bkg (np.ndarray): Background map\n        nh (np.ndarray): Hydrogen column density map\n        wcs (astropy.wcs.WCS): WCS object\n        header (astropy.io.fits.Header): Header object\n        degree_per_pixel (astropy.units.Quantity): Angular size of a pixel in degrees\n        kpc_per_pixel (astropy.units.Quantity): Angular size of a pixel in kpc\n        shape (tuple): Shape of the image\n        x_c (float): X coordinate of the cluster center\n        y_c (float): Y coordinate of the cluster center\n        y_ref (np.ndarray): Y coordinate of the image\n        x_ref (np.ndarray): X coordinate of the image\n        coords (astropy.coordinates.SkyCoord): Coordinates of the image\n        z (float): Redshift of the cluster\n        r_500 (astropy.units.Quantity): Radius of the cluster at 500 times the critical density.\n        t_500 (astropy.units.Quantity): Angular radius of the cluster at 500 times the critical density.\n        center (astropy.coordinates.SkyCoord): Coordinates of the cluster center\n        name (str): Name of the cluster\n        imglink (str): Path to the image file\n        explink (str): Path to the exposure map file\n        bkglink (str): Path to the background map file\n        cosmo (astropy.cosmology.FlatLambdaCDM): Cosmology used to compute the angular and physical sizes\n        regions (regions.Regions): Regions to exclude from the analysis\n        unmasked_img (np.ndarray): Unmasked image data\n        unmasked_exposure (np.ndarray): Unmasked exposure map\n    \"\"\"\n\n    cosmo: Cosmology\n\n    def __init__(self, imglink: str,\n                 explink: str=None,\n                 bkglink: str=None,\n                 reglink: str=None,\n                 nhlink: str=None,\n                 redshift: float=0.,\n                 r_500: u.Quantity|None=None,\n                 t_500: u.Quantity|None=None,\n                 ra: float|u.Quantity=None,\n                 dec: float|u.Quantity=None,\n                 name: str=None):\n        r\"\"\"\n        Constructor for the Cluster class.\n\n        Parameters:\n            imglink (str): Path to the image file\n            explink (str): Path to the exposure map file\n            bkglink (str): Path to the background map file\n            redshift (float): Redshift of the cluster\n            r_500 (astropy.units.Quantity): Radius of the cluster at 500 times the critical density.  Either r_500 or t_500 must be provided.\n            t_500 (astropy.units.Quantity): Angular radius of the cluster at 500 times the critical density.  Either r_500 or t_500 must be provided.\n            ra (float|astropy.units.Quantity): Right ascension of the cluster center\n            dec (float|astropy.units.Quantity): Declination of the cluster center\n            name (str): Name of the cluster\n        \"\"\"\n\n        self.img = fits.getdata(imglink)\n        self.imglink = imglink\n        self.explink = explink\n        self.bkglink = bkglink\n        self.cosmo = FlatLambdaCDM(70, 0.3)\n        self.z = redshift\n        self.name = name\n\n        if r_500 is not None:\n\n            self.r_500 = r_500\n            self.t_500 = (r_500/self.cosmo.kpc_proper_per_arcmin(self.z)).to(u.arcmin)\n\n        elif t_500 is not None:\n\n            self.t_500 = t_500\n            self.r_500 = (t_500*self.cosmo.kpc_proper_per_arcmin(self.z)).to(u.kpc)\n\n        self.center = SkyCoord(ra=ra, dec=dec, unit='degree')\n\n        head = fits.getheader(imglink)\n        self.header = head\n        self.wcs = WCS(head, relax=False)\n\n        if 'CDELT2' in head:\n            self.degree_per_pixel = head['CDELT2'] * u.deg / u.pix\n        elif 'CD2_2' in head:\n            self.degree_per_pixel = head['CD2_2'] * u.deg / u.pix\n\n        self.kpc_per_pixel = self.cosmo.kpc_proper_per_arcmin(self.z) * self.degree_per_pixel\n        self.kpc_per_pixel = self.kpc_per_pixel.to(u.kpc / u.pixel)\n        self.shape = self.img.shape\n        self.exp = fits.getdata(explink, memmap=False) if explink is not None else np.ones(self.shape)\n        self.bkg = fits.getdata(bkglink, memmap=False) if bkglink is not None else np.zeros(self.shape)\n\n        self.exp *= self.kpc_per_pixel.value ** 2\n        self.unmasked_img = copy.deepcopy(self.img)\n        self.img *= (self.exp&gt;0)\n\n        self.x_c, self.y_c = self.center.to_pixel(self.wcs)\n        self.y_ref, self.x_ref = np.indices(self.shape)\n        self.coords = SkyCoord.from_pixel(self.x_ref, self.y_ref, self.wcs)\n\n        self.load_nh(nhlink)\n        self.region(reglink)\n\n    @classmethod\n    def from_catalog_row(cls, row):\n        \"\"\"\n        DEPRECATED: Build a cluster object from a row in the X-COP catalog\n        \"\"\"\n\n        name = row['NAME']\n\n        imglink = os.path.join(config.DATA_PATH, f'XCOP/{name}/mosaic_{name.lower()}.fits.gz')\n        explink = os.path.join(config.DATA_PATH, f'XCOP/{name}/mosaic_{name.lower()}_expo.fits.gz')\n        bkglink = os.path.join(config.DATA_PATH, f'XCOP/{name}/mosaic_{name.lower()}_bkg.fits.gz')\n\n        instance = cls(imglink,\n                       explink=explink,\n                       bkglink=bkglink,\n                       redshift=row['REDSHIFT'],\n                       r_500=row['R500_HSE'] * u.kpc,\n                       ra=row['RA'],\n                       dec=row['DEC'],\n                       name=name)\n\n        instance.region(os.path.join(config.DATA_PATH, f'XCOP/{name}/src_ps.reg'))\n        instance.load_nh(os.path.join(config.DATA_PATH, f'XCOP/{name}/{name}_nh.fits'))\n\n        return instance\n\n    def region(self, region_file):\n        \"\"\"\n        Filter out regions provided in an input DS9 region file\n\n        Parameters:\n            region_file (str): Path to region file. Accepted region file formats are fk5 and image.\n        \"\"\"\n\n        regions = Regions.read(region_file)\n        mask = np.ones(self.shape)*(self.exp&gt;0.)\n\n        for region in regions:\n\n            if isinstance(region, SkyRegion):\n                # Turn a sky region into a pixel region\n                region = region.to_pixel(self.wcs)\n\n            mask[region.to_mask().to_image(self.shape) &gt; 0] = 0\n\n        #print('Excluded %d sources' % (len(regions)))\n        self.unmasked_exposure = copy.deepcopy(self.exp)\n        self.img = self.img*mask\n        self.exp = self.exp*mask\n        self.regions = regions\n\n    def load_nh(self, nh_file):\n        \"\"\"\n        Load the hydrogen column density map\n\n        Parameters:\n            nh_file (str): Path to the hydrogen column density map file\n        \"\"\"\n\n        nh = fits.getdata(nh_file)\n        assert nh.shape == self.shape\n        self.nh = nh\n\n    def voronoi(self, voronoi_file, rebin_factor=5, exclusion=1, t_500_percent=1.):\n        \"\"\"\n        Load the voronoi binning map. It must be produced using the vorbin package.\n        See https://pypi.org/project/vorbin/ for more information and especially\n        the scripts/voronoi.ipynb notebook for an example of how to generate the map.\n\n        Rebin the data using the previously loaded voronoi map.\n        It assumes that the Voronoi binning algorithm has been run on the data with a\n        first rough 4x4 rebinning, which I used to accelerate the computation of maps.\n\n        !!! danger\n            This function contains a lot of hard-coded values that should be changed.\n            It requires the user to precisely remember how the data was processed before\n            using the `vorbin`package and try to applies the same to the untouched cluster\n            data.\n\n        Parameters:\n            voronoi_file (str): Path to the voronoi map file\n            rebin_factor (int): Rebinning factor\n            exclusion (float): factor used in `reduce_to_r500`\n            t_500_percent (float): Radius of the cluster in units of t_500 when selecting pixels\n\n        Returns:\n            cluster: A new Cluster object with the rebinned data.\n\n        !!! warning\n            This function does not act in place, and instead return a new object.\n        \"\"\"\n\n        new_data = self.reduce_to_r500(exclusion).rebin(rebin_factor)\n\n        new_data.voronoi = np.loadtxt(voronoi_file)\n\n        indexes = (new_data.exp &gt; 0) &amp; (new_data.coords.separation(new_data.center) &lt; new_data.t_500*t_500_percent)\n        y_ref, x_ref = new_data.y_ref[indexes], new_data.x_ref[indexes]\n        img = np.array(new_data.img[indexes].astype(int))\n        exp = np.array(new_data.exp[indexes].astype(np.float32))\n\n        img *= (exp &gt; 0.)\n        bkg = np.array(new_data.bkg[indexes].astype(np.float32))\n        nH = np.array(new_data.nh[indexes].astype(np.float32))\n        bin_number = np.array(new_data.voronoi.astype(int))\n\n        unique_bin = np.unique(bin_number)\n        x_ref_reduced = np.empty_like(unique_bin, dtype=np.float32)\n        y_ref_reduced = np.empty_like(unique_bin, dtype=np.float32)\n        img_reduced = np.empty_like(unique_bin)\n        exp_reduced = np.empty_like(unique_bin, dtype=np.float32)\n        bkg_reduced = np.empty_like(unique_bin)\n        nH_reduced = np.empty_like(unique_bin, dtype=np.float32)\n\n        for i, number in enumerate(unique_bin):\n            bin_index = (bin_number == number)\n\n            x_ref_reduced[i] = np.mean(x_ref[bin_index])\n            y_ref_reduced[i] = np.mean(y_ref[bin_index])\n            nH_reduced[i] = np.mean(nH[bin_index])\n            img_reduced[i] = np.sum(img[bin_index])\n            exp_reduced[i] = np.sum(exp[bin_index])\n            bkg_reduced[i] = np.sum(bkg[bin_index])\n\n        new_data.img = img_reduced\n        new_data.exp = exp_reduced\n        new_data.bkg = bkg_reduced\n        new_data.nh = nH_reduced\n        new_data.x_ref = x_ref_reduced\n        new_data.y_ref = y_ref_reduced\n        new_data.shape = unique_bin.shape\n\n        return new_data\n\n    def flatten(self, r_500_percent: float=1.):\n        \"\"\"\n        Flatten the data in a 1D array and remove pixels outside the specified radius.\n        It also removes pixels with no exposure.\n\n        Parameters:\n            r_500_percent (float): Radius of the cluster in units of r_500\n\n        Returns:\n            cluster: A new Cluster object with the flattened data.\n\n        !!! warning\n            This function does not act in place, and instead return a new object.\n        \"\"\"\n\n\n        new_data = copy.deepcopy(self)\n        index = (new_data.exp &gt; 0) &amp; (new_data.center.separation(new_data.coords) &lt; new_data.t_500 * r_500_percent)\n        new_data.img = new_data.img[index]\n        new_data.exp = new_data.exp[index]\n        new_data.bkg = new_data.bkg[index]\n        new_data.nh = new_data.nh[index]\n        new_data.shape = new_data.img.shape\n\n        new_data.y_ref, new_data.x_ref = new_data.y_ref[index], new_data.x_ref[index]\n\n        new_data.index = index \n\n        return new_data\n\n    def rebin(self, factor: int):\n        \"\"\"\n        Rebin the data by a factor of `factor`. It uses the astropy block_reduce function.\n\n        Parameters:\n            factor (int): Rebinning factor\n\n        Returns:\n            cluster: A new Cluster object with the rebinned data.\n\n        !!! warning\n            This function does not act in place, and instead return a new object.\n        \"\"\"\n\n        def sum_reduce(vec, factor):\n\n            return np.nan_to_num(block_reduce(np.where(self.exp &gt; 0, vec, np.nan), factor))\n\n        def sum_reduce_unmasked(vec, factor):\n\n            return np.nan_to_num(block_reduce(np.where(self.unmasked_exposure &gt; 0, vec, np.nan), factor))\n\n        def mean_reduce(vec, factor):\n\n            return np.nan_to_num(block_reduce(np.where(self.exp &gt; 0, vec, np.nan), factor, np.mean))\n\n        new_data = copy.deepcopy(self)\n        new_data.wcs = new_data.wcs[::factor, ::factor]\n        new_data.img = sum_reduce(self.img, factor)\n        new_data.exp = sum_reduce(self.exp, factor)\n        new_data.bkg = sum_reduce(self.bkg, factor)\n        new_data.nh = mean_reduce(self.nh, factor)\n        new_data.unmasked_img = sum_reduce_unmasked(self.unmasked_img, factor)\n        new_data.unmasked_exposure = sum_reduce_unmasked(self.unmasked_exposure, factor)\n        new_data.shape = new_data.img.shape\n        new_data.kpc_per_pixel *= factor\n        new_data.degree_per_pixel *= factor\n\n        new_data.x_c, new_data.y_c = new_data.center.to_pixel(new_data.wcs)\n        new_data.y_ref, new_data.x_ref = np.indices(new_data.shape)\n        new_data.coords = SkyCoord.from_pixel(new_data.x_ref, new_data.y_ref, new_data.wcs)\n\n        return new_data\n\n    def reduce_fov(self, mean_model, r500_cut):\n        \"\"\"\n        Reduce the field of view to a given radius in units of r_500, using the best-fit\n        mean model, which includes ellipticity for the cluster shape.\n\n        Parameters:\n            mean_model (MeanModel): Best-fit mean model\n            r500_cut (float): Radius in units of r_500\n\n        Returns:\n            cluster: A new Cluster object with the reduced field of view.\n\n        !!! warning\n            This function does not act in place, and instead return a new object.\n        \"\"\"\n\n\n        rows = np.any(mean_model.rad&lt;r500_cut, axis=1)\n        cols = np.any(mean_model.rad&lt;r500_cut, axis=0)\n        rmin, rmax = np.where(rows)[0][[0, -1]]\n        cmin, cmax = np.where(cols)[0][[0, -1]]\n\n\n        new_data = copy.deepcopy(self)\n        new_data.wcs = new_data.wcs[rmin:rmax, cmin:cmax]\n        new_data.img = self.img[rmin:rmax, cmin:cmax]\n        new_data.exp = self.exp[rmin:rmax, cmin:cmax]\n        new_data.bkg = self.bkg[rmin:rmax, cmin:cmax]\n        new_data.nh = self.nh[rmin:rmax, cmin:cmax]\n        new_data.unmasked_exposure = self.unmasked_exposure[rmin:rmax, cmin:cmax]\n        new_data.unmasked_img = self.unmasked_img[rmin:rmax, cmin:cmax]\n        new_data.shape = new_data.img.shape\n\n        new_data.x_c, new_data.y_c = new_data.center.to_pixel(new_data.wcs)\n        new_data.y_ref, new_data.x_ref = np.indices(new_data.shape)\n        new_data.coords = SkyCoord.from_pixel(new_data.x_ref, new_data.y_ref, new_data.wcs)\n\n        return new_data\n\n    def reduce_to_r500(self, r500_cut=1.):\n        \"\"\"\n        Reduce the field of view to a given radius in units of r_500. This does not\n        take into account the ellipticity of the cluster, and simply assumes a circular\n        symetry and uses the first proposed center to compute the radius.\n\n        Parameters:\n            r500_cut (float): Radius in units of r_500\n\n        Returns:\n            cluster: A new Cluster object with the reduced field of view.\n\n        !!! warning\n            This function does not act in place, and instead return a new object.\n        \"\"\"\n\n        valid = (self.exp&gt;0)&amp;(self.coords.separation(self.center) &lt; self.t_500*r500_cut)\n        rows = np.any(valid, axis=1)\n        cols = np.any(valid, axis=0)\n        rmin, rmax = np.where(rows)[0][[0, -1]]\n        cmin, cmax = np.where(cols)[0][[0, -1]]\n\n\n        new_data = copy.deepcopy(self)\n        new_data.wcs = new_data.wcs[rmin:rmax, cmin:cmax]\n        new_data.img = self.img[rmin:rmax, cmin:cmax]\n        new_data.exp = self.exp[rmin:rmax, cmin:cmax]\n        new_data.bkg = self.bkg[rmin:rmax, cmin:cmax]\n        new_data.nh = self.nh[rmin:rmax, cmin:cmax]\n        new_data.unmasked_exposure = self.unmasked_exposure[rmin:rmax, cmin:cmax]\n        new_data.unmasked_img = self.unmasked_img[rmin:rmax, cmin:cmax]\n        new_data.shape = new_data.img.shape\n\n        new_data.x_c, new_data.y_c = new_data.center.to_pixel(new_data.wcs)\n        new_data.y_ref, new_data.x_ref = np.indices(new_data.shape)\n        new_data.coords = SkyCoord.from_pixel(new_data.x_ref, new_data.y_ref, new_data.wcs)\n\n        return new_data\n\n    def plot_cluster(self):\n        \"\"\"\n        Helper function to plot the observation components\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n        import cmasher as cmr\n        from matplotlib.colors import LogNorm\n\n        fig, axs = plt.subplots(\n            figsize=(12, 5),\n            nrows=1,\n            ncols=3,\n            subplot_kw={'projection': self.wcs}\n        )\n\n        img_plot = axs[0].imshow(\n            np.where(self.exp &gt; 0, self.img, np.nan),\n            cmap=cmr.cosmic,\n            norm=LogNorm(vmin=0.1)\n        )\n\n        exp_plot = axs[1].imshow(\n            np.where(self.exp &gt; 0, self.exp, np.nan),\n            cmap=cmr.ember\n        )\n\n        bkg_plot = axs[2].imshow(\n            np.where(self.exp &gt; 0, self.bkg, np.nan),\n            cmap=cmr.cosmic\n        )\n\n        plt.colorbar(\n            mappable=img_plot,\n            ax=axs[0],\n            location='bottom',\n            label=\"Image (Photons)\"\n        )\n\n        plt.colorbar(\n            mappable=exp_plot,\n            ax=axs[1],\n            location='bottom',\n            label=r\"Effective exposure (seconds $\\times$ kpc$^2$)\"\n        )\n\n        plt.colorbar(\n            mappable=bkg_plot,\n            ax=axs[2],\n            location='bottom',\n            label=\"Background (Photons)\"\n        )\n\n        plt.tight_layout()\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.__init__","title":"<code>__init__(imglink, explink=None, bkglink=None, reglink=None, nhlink=None, redshift=0.0, r_500=None, t_500=None, ra=None, dec=None, name=None)</code>","text":"<p>Constructor for the Cluster class.</p> <p>Parameters:</p> Name Type Description Default <code>imglink</code> <code>str</code> <p>Path to the image file</p> required <code>explink</code> <code>str</code> <p>Path to the exposure map file</p> <code>None</code> <code>bkglink</code> <code>str</code> <p>Path to the background map file</p> <code>None</code> <code>redshift</code> <code>float</code> <p>Redshift of the cluster</p> <code>0.0</code> <code>r_500</code> <code>Quantity</code> <p>Radius of the cluster at 500 times the critical density.  Either r_500 or t_500 must be provided.</p> <code>None</code> <code>t_500</code> <code>Quantity</code> <p>Angular radius of the cluster at 500 times the critical density.  Either r_500 or t_500 must be provided.</p> <code>None</code> <code>ra</code> <code>float | Quantity</code> <p>Right ascension of the cluster center</p> <code>None</code> <code>dec</code> <code>float | Quantity</code> <p>Declination of the cluster center</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the cluster</p> <code>None</code> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def __init__(self, imglink: str,\n             explink: str=None,\n             bkglink: str=None,\n             reglink: str=None,\n             nhlink: str=None,\n             redshift: float=0.,\n             r_500: u.Quantity|None=None,\n             t_500: u.Quantity|None=None,\n             ra: float|u.Quantity=None,\n             dec: float|u.Quantity=None,\n             name: str=None):\n    r\"\"\"\n    Constructor for the Cluster class.\n\n    Parameters:\n        imglink (str): Path to the image file\n        explink (str): Path to the exposure map file\n        bkglink (str): Path to the background map file\n        redshift (float): Redshift of the cluster\n        r_500 (astropy.units.Quantity): Radius of the cluster at 500 times the critical density.  Either r_500 or t_500 must be provided.\n        t_500 (astropy.units.Quantity): Angular radius of the cluster at 500 times the critical density.  Either r_500 or t_500 must be provided.\n        ra (float|astropy.units.Quantity): Right ascension of the cluster center\n        dec (float|astropy.units.Quantity): Declination of the cluster center\n        name (str): Name of the cluster\n    \"\"\"\n\n    self.img = fits.getdata(imglink)\n    self.imglink = imglink\n    self.explink = explink\n    self.bkglink = bkglink\n    self.cosmo = FlatLambdaCDM(70, 0.3)\n    self.z = redshift\n    self.name = name\n\n    if r_500 is not None:\n\n        self.r_500 = r_500\n        self.t_500 = (r_500/self.cosmo.kpc_proper_per_arcmin(self.z)).to(u.arcmin)\n\n    elif t_500 is not None:\n\n        self.t_500 = t_500\n        self.r_500 = (t_500*self.cosmo.kpc_proper_per_arcmin(self.z)).to(u.kpc)\n\n    self.center = SkyCoord(ra=ra, dec=dec, unit='degree')\n\n    head = fits.getheader(imglink)\n    self.header = head\n    self.wcs = WCS(head, relax=False)\n\n    if 'CDELT2' in head:\n        self.degree_per_pixel = head['CDELT2'] * u.deg / u.pix\n    elif 'CD2_2' in head:\n        self.degree_per_pixel = head['CD2_2'] * u.deg / u.pix\n\n    self.kpc_per_pixel = self.cosmo.kpc_proper_per_arcmin(self.z) * self.degree_per_pixel\n    self.kpc_per_pixel = self.kpc_per_pixel.to(u.kpc / u.pixel)\n    self.shape = self.img.shape\n    self.exp = fits.getdata(explink, memmap=False) if explink is not None else np.ones(self.shape)\n    self.bkg = fits.getdata(bkglink, memmap=False) if bkglink is not None else np.zeros(self.shape)\n\n    self.exp *= self.kpc_per_pixel.value ** 2\n    self.unmasked_img = copy.deepcopy(self.img)\n    self.img *= (self.exp&gt;0)\n\n    self.x_c, self.y_c = self.center.to_pixel(self.wcs)\n    self.y_ref, self.x_ref = np.indices(self.shape)\n    self.coords = SkyCoord.from_pixel(self.x_ref, self.y_ref, self.wcs)\n\n    self.load_nh(nhlink)\n    self.region(reglink)\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.flatten","title":"<code>flatten(r_500_percent=1.0)</code>","text":"<p>Flatten the data in a 1D array and remove pixels outside the specified radius. It also removes pixels with no exposure.</p> <p>Parameters:</p> Name Type Description Default <code>r_500_percent</code> <code>float</code> <p>Radius of the cluster in units of r_500</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>cluster</code> <p>A new Cluster object with the flattened data.</p> <p>Warning</p> <p>This function does not act in place, and instead return a new object.</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def flatten(self, r_500_percent: float=1.):\n    \"\"\"\n    Flatten the data in a 1D array and remove pixels outside the specified radius.\n    It also removes pixels with no exposure.\n\n    Parameters:\n        r_500_percent (float): Radius of the cluster in units of r_500\n\n    Returns:\n        cluster: A new Cluster object with the flattened data.\n\n    !!! warning\n        This function does not act in place, and instead return a new object.\n    \"\"\"\n\n\n    new_data = copy.deepcopy(self)\n    index = (new_data.exp &gt; 0) &amp; (new_data.center.separation(new_data.coords) &lt; new_data.t_500 * r_500_percent)\n    new_data.img = new_data.img[index]\n    new_data.exp = new_data.exp[index]\n    new_data.bkg = new_data.bkg[index]\n    new_data.nh = new_data.nh[index]\n    new_data.shape = new_data.img.shape\n\n    new_data.y_ref, new_data.x_ref = new_data.y_ref[index], new_data.x_ref[index]\n\n    new_data.index = index \n\n    return new_data\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.from_catalog_row","title":"<code>from_catalog_row(row)</code>  <code>classmethod</code>","text":"<p>DEPRECATED: Build a cluster object from a row in the X-COP catalog</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>@classmethod\ndef from_catalog_row(cls, row):\n    \"\"\"\n    DEPRECATED: Build a cluster object from a row in the X-COP catalog\n    \"\"\"\n\n    name = row['NAME']\n\n    imglink = os.path.join(config.DATA_PATH, f'XCOP/{name}/mosaic_{name.lower()}.fits.gz')\n    explink = os.path.join(config.DATA_PATH, f'XCOP/{name}/mosaic_{name.lower()}_expo.fits.gz')\n    bkglink = os.path.join(config.DATA_PATH, f'XCOP/{name}/mosaic_{name.lower()}_bkg.fits.gz')\n\n    instance = cls(imglink,\n                   explink=explink,\n                   bkglink=bkglink,\n                   redshift=row['REDSHIFT'],\n                   r_500=row['R500_HSE'] * u.kpc,\n                   ra=row['RA'],\n                   dec=row['DEC'],\n                   name=name)\n\n    instance.region(os.path.join(config.DATA_PATH, f'XCOP/{name}/src_ps.reg'))\n    instance.load_nh(os.path.join(config.DATA_PATH, f'XCOP/{name}/{name}_nh.fits'))\n\n    return instance\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.load_nh","title":"<code>load_nh(nh_file)</code>","text":"<p>Load the hydrogen column density map</p> <p>Parameters:</p> Name Type Description Default <code>nh_file</code> <code>str</code> <p>Path to the hydrogen column density map file</p> required Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def load_nh(self, nh_file):\n    \"\"\"\n    Load the hydrogen column density map\n\n    Parameters:\n        nh_file (str): Path to the hydrogen column density map file\n    \"\"\"\n\n    nh = fits.getdata(nh_file)\n    assert nh.shape == self.shape\n    self.nh = nh\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.plot_cluster","title":"<code>plot_cluster()</code>","text":"<p>Helper function to plot the observation components</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def plot_cluster(self):\n    \"\"\"\n    Helper function to plot the observation components\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    import cmasher as cmr\n    from matplotlib.colors import LogNorm\n\n    fig, axs = plt.subplots(\n        figsize=(12, 5),\n        nrows=1,\n        ncols=3,\n        subplot_kw={'projection': self.wcs}\n    )\n\n    img_plot = axs[0].imshow(\n        np.where(self.exp &gt; 0, self.img, np.nan),\n        cmap=cmr.cosmic,\n        norm=LogNorm(vmin=0.1)\n    )\n\n    exp_plot = axs[1].imshow(\n        np.where(self.exp &gt; 0, self.exp, np.nan),\n        cmap=cmr.ember\n    )\n\n    bkg_plot = axs[2].imshow(\n        np.where(self.exp &gt; 0, self.bkg, np.nan),\n        cmap=cmr.cosmic\n    )\n\n    plt.colorbar(\n        mappable=img_plot,\n        ax=axs[0],\n        location='bottom',\n        label=\"Image (Photons)\"\n    )\n\n    plt.colorbar(\n        mappable=exp_plot,\n        ax=axs[1],\n        location='bottom',\n        label=r\"Effective exposure (seconds $\\times$ kpc$^2$)\"\n    )\n\n    plt.colorbar(\n        mappable=bkg_plot,\n        ax=axs[2],\n        location='bottom',\n        label=\"Background (Photons)\"\n    )\n\n    plt.tight_layout()\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.rebin","title":"<code>rebin(factor)</code>","text":"<p>Rebin the data by a factor of <code>factor</code>. It uses the astropy block_reduce function.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>int</code> <p>Rebinning factor</p> required <p>Returns:</p> Name Type Description <code>cluster</code> <p>A new Cluster object with the rebinned data.</p> <p>Warning</p> <p>This function does not act in place, and instead return a new object.</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def rebin(self, factor: int):\n    \"\"\"\n    Rebin the data by a factor of `factor`. It uses the astropy block_reduce function.\n\n    Parameters:\n        factor (int): Rebinning factor\n\n    Returns:\n        cluster: A new Cluster object with the rebinned data.\n\n    !!! warning\n        This function does not act in place, and instead return a new object.\n    \"\"\"\n\n    def sum_reduce(vec, factor):\n\n        return np.nan_to_num(block_reduce(np.where(self.exp &gt; 0, vec, np.nan), factor))\n\n    def sum_reduce_unmasked(vec, factor):\n\n        return np.nan_to_num(block_reduce(np.where(self.unmasked_exposure &gt; 0, vec, np.nan), factor))\n\n    def mean_reduce(vec, factor):\n\n        return np.nan_to_num(block_reduce(np.where(self.exp &gt; 0, vec, np.nan), factor, np.mean))\n\n    new_data = copy.deepcopy(self)\n    new_data.wcs = new_data.wcs[::factor, ::factor]\n    new_data.img = sum_reduce(self.img, factor)\n    new_data.exp = sum_reduce(self.exp, factor)\n    new_data.bkg = sum_reduce(self.bkg, factor)\n    new_data.nh = mean_reduce(self.nh, factor)\n    new_data.unmasked_img = sum_reduce_unmasked(self.unmasked_img, factor)\n    new_data.unmasked_exposure = sum_reduce_unmasked(self.unmasked_exposure, factor)\n    new_data.shape = new_data.img.shape\n    new_data.kpc_per_pixel *= factor\n    new_data.degree_per_pixel *= factor\n\n    new_data.x_c, new_data.y_c = new_data.center.to_pixel(new_data.wcs)\n    new_data.y_ref, new_data.x_ref = np.indices(new_data.shape)\n    new_data.coords = SkyCoord.from_pixel(new_data.x_ref, new_data.y_ref, new_data.wcs)\n\n    return new_data\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.reduce_fov","title":"<code>reduce_fov(mean_model, r500_cut)</code>","text":"<p>Reduce the field of view to a given radius in units of r_500, using the best-fit mean model, which includes ellipticity for the cluster shape.</p> <p>Parameters:</p> Name Type Description Default <code>mean_model</code> <code>MeanModel</code> <p>Best-fit mean model</p> required <code>r500_cut</code> <code>float</code> <p>Radius in units of r_500</p> required <p>Returns:</p> Name Type Description <code>cluster</code> <p>A new Cluster object with the reduced field of view.</p> <p>Warning</p> <p>This function does not act in place, and instead return a new object.</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def reduce_fov(self, mean_model, r500_cut):\n    \"\"\"\n    Reduce the field of view to a given radius in units of r_500, using the best-fit\n    mean model, which includes ellipticity for the cluster shape.\n\n    Parameters:\n        mean_model (MeanModel): Best-fit mean model\n        r500_cut (float): Radius in units of r_500\n\n    Returns:\n        cluster: A new Cluster object with the reduced field of view.\n\n    !!! warning\n        This function does not act in place, and instead return a new object.\n    \"\"\"\n\n\n    rows = np.any(mean_model.rad&lt;r500_cut, axis=1)\n    cols = np.any(mean_model.rad&lt;r500_cut, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n\n    new_data = copy.deepcopy(self)\n    new_data.wcs = new_data.wcs[rmin:rmax, cmin:cmax]\n    new_data.img = self.img[rmin:rmax, cmin:cmax]\n    new_data.exp = self.exp[rmin:rmax, cmin:cmax]\n    new_data.bkg = self.bkg[rmin:rmax, cmin:cmax]\n    new_data.nh = self.nh[rmin:rmax, cmin:cmax]\n    new_data.unmasked_exposure = self.unmasked_exposure[rmin:rmax, cmin:cmax]\n    new_data.unmasked_img = self.unmasked_img[rmin:rmax, cmin:cmax]\n    new_data.shape = new_data.img.shape\n\n    new_data.x_c, new_data.y_c = new_data.center.to_pixel(new_data.wcs)\n    new_data.y_ref, new_data.x_ref = np.indices(new_data.shape)\n    new_data.coords = SkyCoord.from_pixel(new_data.x_ref, new_data.y_ref, new_data.wcs)\n\n    return new_data\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.reduce_to_r500","title":"<code>reduce_to_r500(r500_cut=1.0)</code>","text":"<p>Reduce the field of view to a given radius in units of r_500. This does not take into account the ellipticity of the cluster, and simply assumes a circular symetry and uses the first proposed center to compute the radius.</p> <p>Parameters:</p> Name Type Description Default <code>r500_cut</code> <code>float</code> <p>Radius in units of r_500</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>cluster</code> <p>A new Cluster object with the reduced field of view.</p> <p>Warning</p> <p>This function does not act in place, and instead return a new object.</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def reduce_to_r500(self, r500_cut=1.):\n    \"\"\"\n    Reduce the field of view to a given radius in units of r_500. This does not\n    take into account the ellipticity of the cluster, and simply assumes a circular\n    symetry and uses the first proposed center to compute the radius.\n\n    Parameters:\n        r500_cut (float): Radius in units of r_500\n\n    Returns:\n        cluster: A new Cluster object with the reduced field of view.\n\n    !!! warning\n        This function does not act in place, and instead return a new object.\n    \"\"\"\n\n    valid = (self.exp&gt;0)&amp;(self.coords.separation(self.center) &lt; self.t_500*r500_cut)\n    rows = np.any(valid, axis=1)\n    cols = np.any(valid, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n\n    new_data = copy.deepcopy(self)\n    new_data.wcs = new_data.wcs[rmin:rmax, cmin:cmax]\n    new_data.img = self.img[rmin:rmax, cmin:cmax]\n    new_data.exp = self.exp[rmin:rmax, cmin:cmax]\n    new_data.bkg = self.bkg[rmin:rmax, cmin:cmax]\n    new_data.nh = self.nh[rmin:rmax, cmin:cmax]\n    new_data.unmasked_exposure = self.unmasked_exposure[rmin:rmax, cmin:cmax]\n    new_data.unmasked_img = self.unmasked_img[rmin:rmax, cmin:cmax]\n    new_data.shape = new_data.img.shape\n\n    new_data.x_c, new_data.y_c = new_data.center.to_pixel(new_data.wcs)\n    new_data.y_ref, new_data.x_ref = np.indices(new_data.shape)\n    new_data.coords = SkyCoord.from_pixel(new_data.x_ref, new_data.y_ref, new_data.wcs)\n\n    return new_data\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.region","title":"<code>region(region_file)</code>","text":"<p>Filter out regions provided in an input DS9 region file</p> <p>Parameters:</p> Name Type Description Default <code>region_file</code> <code>str</code> <p>Path to region file. Accepted region file formats are fk5 and image.</p> required Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def region(self, region_file):\n    \"\"\"\n    Filter out regions provided in an input DS9 region file\n\n    Parameters:\n        region_file (str): Path to region file. Accepted region file formats are fk5 and image.\n    \"\"\"\n\n    regions = Regions.read(region_file)\n    mask = np.ones(self.shape)*(self.exp&gt;0.)\n\n    for region in regions:\n\n        if isinstance(region, SkyRegion):\n            # Turn a sky region into a pixel region\n            region = region.to_pixel(self.wcs)\n\n        mask[region.to_mask().to_image(self.shape) &gt; 0] = 0\n\n    #print('Excluded %d sources' % (len(regions)))\n    self.unmasked_exposure = copy.deepcopy(self.exp)\n    self.img = self.img*mask\n    self.exp = self.exp*mask\n    self.regions = regions\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.cluster.Cluster.voronoi","title":"<code>voronoi(voronoi_file, rebin_factor=5, exclusion=1, t_500_percent=1.0)</code>","text":"<p>Load the voronoi binning map. It must be produced using the vorbin package. See https://pypi.org/project/vorbin/ for more information and especially the scripts/voronoi.ipynb notebook for an example of how to generate the map.</p> <p>Rebin the data using the previously loaded voronoi map. It assumes that the Voronoi binning algorithm has been run on the data with a first rough 4x4 rebinning, which I used to accelerate the computation of maps.</p> <p>Danger</p> <p>This function contains a lot of hard-coded values that should be changed. It requires the user to precisely remember how the data was processed before using the <code>vorbin</code>package and try to applies the same to the untouched cluster data.</p> <p>Parameters:</p> Name Type Description Default <code>voronoi_file</code> <code>str</code> <p>Path to the voronoi map file</p> required <code>rebin_factor</code> <code>int</code> <p>Rebinning factor</p> <code>5</code> <code>exclusion</code> <code>float</code> <p>factor used in <code>reduce_to_r500</code></p> <code>1</code> <code>t_500_percent</code> <code>float</code> <p>Radius of the cluster in units of t_500 when selecting pixels</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>cluster</code> <p>A new Cluster object with the rebinned data.</p> <p>Warning</p> <p>This function does not act in place, and instead return a new object.</p> Source code in <code>src/xsb_fluc/data/cluster.py</code> <pre><code>def voronoi(self, voronoi_file, rebin_factor=5, exclusion=1, t_500_percent=1.):\n    \"\"\"\n    Load the voronoi binning map. It must be produced using the vorbin package.\n    See https://pypi.org/project/vorbin/ for more information and especially\n    the scripts/voronoi.ipynb notebook for an example of how to generate the map.\n\n    Rebin the data using the previously loaded voronoi map.\n    It assumes that the Voronoi binning algorithm has been run on the data with a\n    first rough 4x4 rebinning, which I used to accelerate the computation of maps.\n\n    !!! danger\n        This function contains a lot of hard-coded values that should be changed.\n        It requires the user to precisely remember how the data was processed before\n        using the `vorbin`package and try to applies the same to the untouched cluster\n        data.\n\n    Parameters:\n        voronoi_file (str): Path to the voronoi map file\n        rebin_factor (int): Rebinning factor\n        exclusion (float): factor used in `reduce_to_r500`\n        t_500_percent (float): Radius of the cluster in units of t_500 when selecting pixels\n\n    Returns:\n        cluster: A new Cluster object with the rebinned data.\n\n    !!! warning\n        This function does not act in place, and instead return a new object.\n    \"\"\"\n\n    new_data = self.reduce_to_r500(exclusion).rebin(rebin_factor)\n\n    new_data.voronoi = np.loadtxt(voronoi_file)\n\n    indexes = (new_data.exp &gt; 0) &amp; (new_data.coords.separation(new_data.center) &lt; new_data.t_500*t_500_percent)\n    y_ref, x_ref = new_data.y_ref[indexes], new_data.x_ref[indexes]\n    img = np.array(new_data.img[indexes].astype(int))\n    exp = np.array(new_data.exp[indexes].astype(np.float32))\n\n    img *= (exp &gt; 0.)\n    bkg = np.array(new_data.bkg[indexes].astype(np.float32))\n    nH = np.array(new_data.nh[indexes].astype(np.float32))\n    bin_number = np.array(new_data.voronoi.astype(int))\n\n    unique_bin = np.unique(bin_number)\n    x_ref_reduced = np.empty_like(unique_bin, dtype=np.float32)\n    y_ref_reduced = np.empty_like(unique_bin, dtype=np.float32)\n    img_reduced = np.empty_like(unique_bin)\n    exp_reduced = np.empty_like(unique_bin, dtype=np.float32)\n    bkg_reduced = np.empty_like(unique_bin)\n    nH_reduced = np.empty_like(unique_bin, dtype=np.float32)\n\n    for i, number in enumerate(unique_bin):\n        bin_index = (bin_number == number)\n\n        x_ref_reduced[i] = np.mean(x_ref[bin_index])\n        y_ref_reduced[i] = np.mean(y_ref[bin_index])\n        nH_reduced[i] = np.mean(nH[bin_index])\n        img_reduced[i] = np.sum(img[bin_index])\n        exp_reduced[i] = np.sum(exp[bin_index])\n        bkg_reduced[i] = np.sum(bkg[bin_index])\n\n    new_data.img = img_reduced\n    new_data.exp = exp_reduced\n    new_data.bkg = bkg_reduced\n    new_data.nh = nH_reduced\n    new_data.x_ref = x_ref_reduced\n    new_data.y_ref = y_ref_reduced\n    new_data.shape = unique_bin.shape\n\n    return new_data\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.mean_model","title":"<code>xsb_fluc.data.mean_model</code>","text":""},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel","title":"<code>MeanModel</code>","text":"<p>Awfully coded class to handle the results of the mean model fitting.</p> <p>Attributes:</p> Name Type Description <code>data</code> <p>the cluster data.</p> <code>mean_model</code> <p>the mean model function.</p> <code>radius</code> <p>the radius function.</p> <code>angle</code> <p>the angle function.</p> <code>inference_data</code> <p>the inference data.</p> <code>true_image</code> <p>the true image.</p> <code>posterior_median</code> <p>the posterior median.</p> <code>posterior_params</code> <p>the posterior parameters.</p> <code>ellipse_params</code> <p>the ellipse parameters.</p> <code>number_of_samples</code> <p>the number of samples.</p> <code>best_fit</code> <p>the best fit image.</p> Source code in <code>src/xsb_fluc/data/mean_model.py</code> <pre><code>class MeanModel:\n    \"\"\"\n    Awfully coded class to handle the results of the mean model fitting.\n\n    Attributes:\n        data: the cluster data.\n        mean_model: the mean model function.\n        radius: the radius function.\n        angle: the angle function.\n        inference_data: the inference data.\n        true_image: the true image.\n        posterior_median: the posterior median.\n        posterior_params: the posterior parameters.\n        ellipse_params: the ellipse parameters.\n        number_of_samples: the number of samples.\n        best_fit: the best fit image.\n    \"\"\"\n\n    def __init__(self, data: Cluster, inference_data: az.InferenceData, model='all'):\n        \"\"\"\n        Constructor for the `MeanModel` class.\n\n        Parameters:\n            data: the cluster data.\n            inference_data: the inference data.\n            model: (artefact of code from the X-COP paper).\n        \"\"\"\n\n        self.data = data\n        self.mean_model = jax.jit(hk.without_apply_rng(hk.transform(lambda : MockXrayCounts(data)())).apply)\n        self.mean_model_unmasked = jax.jit(hk.without_apply_rng(hk.transform(lambda : MockXrayCountsUnmasked(data)())).apply)\n        self.radius = hk.without_apply_rng(hk.transform(lambda x, y :EllipseRadius.from_data(data)(x, y))).apply\n        self.angle = hk.without_apply_rng(hk.transform(lambda x, y :Angle.from_data(data)(x, y))).apply\n        self.inference_data = inference_data\n        self.true_image = jnp.array(data.img, dtype=jnp.float32)\n        stacked = inference_data.posterior.stack(draws=(\"chain\", \"draw\"))\n        var_name = ['log_ne2', 'log_r_c', 'log_r_s', 'beta', 'epsilon', 'log_bkg','angle', 'eccentricity','x_c', 'y_c']\n        self.posterior_median = self.inference_data.posterior.median()\n        self.posterior_params = {name:jnp.asarray(stacked[name].values) for name in var_name}\n        self.ellipse_params = {'ellipse_radius': \n                            {'angle': jnp.asarray(self.posterior_median['angle']),\n                            'eccentricity': jnp.array(self.posterior_median['eccentricity']),\n                            'x_c': jnp.asarray(self.posterior_median['x_c']),\n                            'y_c': jnp.asarray(self.posterior_median['y_c'])}}\n\n        self.number_of_samples = 10000\n        self.best_fit = self.mean_model(inference_to_params(self.posterior_median))\n        self.model_c = model\n\n    @classmethod\n    def from_data(cls, data: Cluster):\n        \"\"\"\n        Load the mean model associated to a given cluster if it exists.\n        \"\"\"\n\n        name = data.name\n        posterior = az.from_netcdf(os.path.join(config.RESULTS_PATH, f'mean_model/{name}_all.posterior'))\n        return cls(data, posterior)\n\n    @property\n    def best_fit_unmasked(self):\n        return self.mean_model_unmasked(inference_to_params_unmasked(self.posterior_median))\n\n    @property\n    def rad(self):\n        \"\"\"\n        Return best-fit radius for each pixel.\n        \"\"\"\n        median = self.posterior_median\n        ellipse_params = {'ellipse_radius': \n                            {'angle': jnp.asarray(median['angle']),\n                            'eccentricity': jnp.array(median['eccentricity']),\n                            'x_c': jnp.asarray(median['x_c']),\n                            'y_c': jnp.asarray(median['y_c'])}}\n\n        return self.radius(ellipse_params, self.data.x_ref, self.data.y_ref)\n\n\n    @property\n    def ang(self):\n        \"\"\"\n        Return best-fit angle for each pixel.\n        \"\"\"\n        median = self.posterior_median\n        angle_params = {'angle':\n                            {'x_c': jnp.asarray(median['x_c']),\n                             'y_c': jnp.asarray(median['y_c']),\n                             'angle': jnp.asarray(median['angle'])}}\n\n\n        return self.angle(angle_params, self.data.x_ref, self.data.y_ref)\n\n    @property\n    def angle_sample(self):\n        \"\"\"\n        Return a sample of angles for each pixel.\n        \"\"\"\n        angle_params = {'angle':\n                            {'x_c': self.posterior_params['x_c'],\n                             'y_c': self.posterior_params['y_c'],\n                             'angle': self.posterior_params['angle']}}\n\n        def func(pars):\n            return self.angle(pars, self.data.x_ref, self.data.y_ref)\n\n        return jax.vmap(func)(angle_params)\n\n    @property\n    def rad_sample(self):\n        \"\"\"\n        Return a sample of radii for each pixel.\n        \"\"\"\n        ellipse_params = {'ellipse_radius':\n                              {'angle': self.posterior_params['angle'],\n                               'eccentricity': self.posterior_params['eccentricity'],\n                               'x_c': self.posterior_params['x_c'],\n                               'y_c': self.posterior_params['y_c']}}\n\n        def func(pars):\n            return self.radius(pars, self.data.x_ref, self.data.y_ref)\n\n        return jax.vmap(func)(ellipse_params)\n\n\n    @property\n    def rad_circ_sample(self):\n\n        ellipse_params = {'ellipse_radius':\n                              {'angle': 0*self.posterior_params['angle'],\n                               'eccentricity': 0.*self.posterior_params['eccentricity'],\n                               'x_c': self.posterior_params['x_c'],\n                               'y_c': self.posterior_params['y_c']}}\n\n        def func(pars):\n            return self.radius(pars, self.data.x_ref, self.data.y_ref)\n\n        return jax.vmap(func)(ellipse_params)\n\n\n    def compute_rad(self, x, y):\n        median = self.posterior_median\n        ellipse_params = {'ellipse_radius': \n                            {'angle': jnp.asarray(median['angle']),\n                            'eccentricity': jnp.array(median['eccentricity']),\n                            'x_c': jnp.asarray(median['x_c']),\n                            'y_c': jnp.asarray(median['y_c'])}}\n\n        return self.radius(ellipse_params, x, y)\n\n    @property\n    def fluctuation_absolute(self):\n        \"\"\"\n        Return the absolute fluctuation map.\n        \"\"\"\n        exp = jnp.asarray(self.data.exp)\n        img = jnp.asarray(self.true_image)\n        fit = jnp.asarray(self.best_fit)\n\n        return jnp.where(exp&gt;0., (img - fit)/(2*exp), 0.)\n\n    @property\n    def fluctuation_relative(self):\n        \"\"\"\n        Return the relative fluctuation map.\n        \"\"\"\n        return jnp.where(self.data.exp &gt; 0., jnp.nan_to_num(jnp.abs(self.true_image)/jnp.abs(self.best_fit)), 0.)\n\n    def power_spectrum_absolute(self, scales=np.geomspace(0.05, 1., 20),mask=None):\n        \"\"\"\n        Compute the absolute power spectrum with a given mask.\n\n        Parameters:\n            scales: array of scales to compute the power spectrum.\n            mask: mask to apply to the data.\n\n        !!! warning\n            This function might not work ?\n        \"\"\"\n\n        power_spectrum = hk.without_apply_rng(hk.transform(lambda img: PowerSpectrum(self.data, mask=mask)(img, scales)))\n\n        return power_spectrum.apply(None, self.fluctuation_absolute)\n\n    def power_spectrum_relative(self, mask=None):\n        \"\"\"\n        Compute the relative power spectrum with a given mask.\n\n        Parameters:\n            scales: array of scales to compute the power spectrum.\n            mask: mask to apply to the data.\n\n        !!! warning\n            This function might not work ?\n        \"\"\"\n        scales = np.geomspace(0.05, 1., 20)\n        power_spectrum = hk.without_apply_rng(hk.transform(lambda img: PowerSpectrum(self.data, mask=mask)(img, scales)))\n\n        return power_spectrum.apply(None, self.fluctuation_relative)\n\n    def sample(self, size, freeze=False):\n\n        if not freeze:\n\n            samples = rng.choice(self.number_of_samples, size=size, replace=False)\n            return {key: value[samples] for key, value in self.posterior_params.items()}\n\n        else:\n\n            return {key: jnp.median(value)*jnp.ones((size,)) for key, value in self.posterior_params.items()}\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.ang","title":"<code>ang</code>  <code>property</code>","text":"<p>Return best-fit angle for each pixel.</p>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.angle_sample","title":"<code>angle_sample</code>  <code>property</code>","text":"<p>Return a sample of angles for each pixel.</p>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.fluctuation_absolute","title":"<code>fluctuation_absolute</code>  <code>property</code>","text":"<p>Return the absolute fluctuation map.</p>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.fluctuation_relative","title":"<code>fluctuation_relative</code>  <code>property</code>","text":"<p>Return the relative fluctuation map.</p>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.rad","title":"<code>rad</code>  <code>property</code>","text":"<p>Return best-fit radius for each pixel.</p>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.rad_sample","title":"<code>rad_sample</code>  <code>property</code>","text":"<p>Return a sample of radii for each pixel.</p>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.__init__","title":"<code>__init__(data, inference_data, model='all')</code>","text":"<p>Constructor for the <code>MeanModel</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Cluster</code> <p>the cluster data.</p> required <code>inference_data</code> <code>InferenceData</code> <p>the inference data.</p> required <code>model</code> <p>(artefact of code from the X-COP paper).</p> <code>'all'</code> Source code in <code>src/xsb_fluc/data/mean_model.py</code> <pre><code>def __init__(self, data: Cluster, inference_data: az.InferenceData, model='all'):\n    \"\"\"\n    Constructor for the `MeanModel` class.\n\n    Parameters:\n        data: the cluster data.\n        inference_data: the inference data.\n        model: (artefact of code from the X-COP paper).\n    \"\"\"\n\n    self.data = data\n    self.mean_model = jax.jit(hk.without_apply_rng(hk.transform(lambda : MockXrayCounts(data)())).apply)\n    self.mean_model_unmasked = jax.jit(hk.without_apply_rng(hk.transform(lambda : MockXrayCountsUnmasked(data)())).apply)\n    self.radius = hk.without_apply_rng(hk.transform(lambda x, y :EllipseRadius.from_data(data)(x, y))).apply\n    self.angle = hk.without_apply_rng(hk.transform(lambda x, y :Angle.from_data(data)(x, y))).apply\n    self.inference_data = inference_data\n    self.true_image = jnp.array(data.img, dtype=jnp.float32)\n    stacked = inference_data.posterior.stack(draws=(\"chain\", \"draw\"))\n    var_name = ['log_ne2', 'log_r_c', 'log_r_s', 'beta', 'epsilon', 'log_bkg','angle', 'eccentricity','x_c', 'y_c']\n    self.posterior_median = self.inference_data.posterior.median()\n    self.posterior_params = {name:jnp.asarray(stacked[name].values) for name in var_name}\n    self.ellipse_params = {'ellipse_radius': \n                        {'angle': jnp.asarray(self.posterior_median['angle']),\n                        'eccentricity': jnp.array(self.posterior_median['eccentricity']),\n                        'x_c': jnp.asarray(self.posterior_median['x_c']),\n                        'y_c': jnp.asarray(self.posterior_median['y_c'])}}\n\n    self.number_of_samples = 10000\n    self.best_fit = self.mean_model(inference_to_params(self.posterior_median))\n    self.model_c = model\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.from_data","title":"<code>from_data(data)</code>  <code>classmethod</code>","text":"<p>Load the mean model associated to a given cluster if it exists.</p> Source code in <code>src/xsb_fluc/data/mean_model.py</code> <pre><code>@classmethod\ndef from_data(cls, data: Cluster):\n    \"\"\"\n    Load the mean model associated to a given cluster if it exists.\n    \"\"\"\n\n    name = data.name\n    posterior = az.from_netcdf(os.path.join(config.RESULTS_PATH, f'mean_model/{name}_all.posterior'))\n    return cls(data, posterior)\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.power_spectrum_absolute","title":"<code>power_spectrum_absolute(scales=np.geomspace(0.05, 1.0, 20), mask=None)</code>","text":"<p>Compute the absolute power spectrum with a given mask.</p> <p>Parameters:</p> Name Type Description Default <code>scales</code> <p>array of scales to compute the power spectrum.</p> <code>geomspace(0.05, 1.0, 20)</code> <code>mask</code> <p>mask to apply to the data.</p> <code>None</code> <p>Warning</p> <p>This function might not work ?</p> Source code in <code>src/xsb_fluc/data/mean_model.py</code> <pre><code>def power_spectrum_absolute(self, scales=np.geomspace(0.05, 1., 20),mask=None):\n    \"\"\"\n    Compute the absolute power spectrum with a given mask.\n\n    Parameters:\n        scales: array of scales to compute the power spectrum.\n        mask: mask to apply to the data.\n\n    !!! warning\n        This function might not work ?\n    \"\"\"\n\n    power_spectrum = hk.without_apply_rng(hk.transform(lambda img: PowerSpectrum(self.data, mask=mask)(img, scales)))\n\n    return power_spectrum.apply(None, self.fluctuation_absolute)\n</code></pre>"},{"location":"references/data/#xsb_fluc.data.mean_model.MeanModel.power_spectrum_relative","title":"<code>power_spectrum_relative(mask=None)</code>","text":"<p>Compute the relative power spectrum with a given mask.</p> <p>Parameters:</p> Name Type Description Default <code>scales</code> <p>array of scales to compute the power spectrum.</p> required <code>mask</code> <p>mask to apply to the data.</p> <code>None</code> <p>Warning</p> <p>This function might not work ?</p> Source code in <code>src/xsb_fluc/data/mean_model.py</code> <pre><code>def power_spectrum_relative(self, mask=None):\n    \"\"\"\n    Compute the relative power spectrum with a given mask.\n\n    Parameters:\n        scales: array of scales to compute the power spectrum.\n        mask: mask to apply to the data.\n\n    !!! warning\n        This function might not work ?\n    \"\"\"\n    scales = np.geomspace(0.05, 1., 20)\n    power_spectrum = hk.without_apply_rng(hk.transform(lambda img: PowerSpectrum(self.data, mask=mask)(img, scales)))\n\n    return power_spectrum.apply(None, self.fluctuation_relative)\n</code></pre>"},{"location":"references/fitting/","title":"fitting","text":""},{"location":"references/fitting/#xsb_fluc.fitting.mean_model","title":"<code>xsb_fluc.fitting.mean_model</code>","text":""},{"location":"references/fitting/#xsb_fluc.fitting.mean_model.MeanModelFitter","title":"<code>MeanModelFitter</code>","text":"<p>This class is meant to fit a 3D model using the X-ray surface</p> Source code in <code>src/xsb_fluc/fitting/mean_model.py</code> <pre><code>class MeanModelFitter:\n    \"\"\"\n    This class is meant to fit a 3D model using the X-ray surface\n    \"\"\"\n\n    def __init__(self,\n                 cluster: Cluster,\n                 n_samples: int = 1000,\n                 n_warmup: int = 1000,\n                 n_chains: int = 1,\n                 model: Literal[None, 'beta', 'circ'] = None,\n                 max_tree_depth: int = 10,\n                 ref_params=None):\n\n        \"\"\"\n        Constructor for the MeanModelFitter which fit the mean model using MCMC\n\n        Parameters:\n            cluster (Cluster): the cluster object which will be fitted\n            n_samples (int): the number of samples\n            n_warmup (int): the number of warmup samples\n            n_chains (int): the number of chains\n            model (Literal[None, 'beta', 'circ']): the model to be fitted. Leave None to use the best.\n            max_tree_depth (int): the maximum recursion depth of the MCMC. Lower to 7 or 5 if too slow.\n            ref_params (dict): the parameters where the chain should be started.\n        \"\"\"\n\n        self.cluster = cluster\n        self.model_var = model\n        self.ref_params = ref_params\n        self.max_tree_depth = max_tree_depth\n\n        if self.model_var == 'beta' or self.model_var == 'circ':\n\n            self.counts = hk.without_apply_rng(hk.transform(lambda: MockXrayCountsBetaModel(self.cluster)()))\n\n        else:\n\n            self.counts = hk.without_apply_rng(hk.transform(lambda: MockXrayCounts(self.cluster)()))\n\n        self.mcmc_config = {'num_samples': n_samples,\n                            'num_warmup': n_warmup,\n                            'num_chains': n_chains,\n                            'progress_bar': True}\n\n    @property\n    def prior(self):\n        \"\"\"\n        Default priors distributions.\n        \"\"\"\n\n        sb = self.cluster.img/self.cluster.exp\n        X = np.stack([self.cluster.x_ref, self.cluster.y_ref])\n        np.average(X, weights=sb, axis=1)\n        X_cov = np.cov(X, aweights=sb)\n\n        eig_val, eig_vec = np.linalg.eig(X_cov)\n        angle = np.arccos(np.dot([1., 0.], eig_vec[:, np.argmin(eig_val)]))\n        (1-(min(eig_val)/max(eig_val))**2)**(1/2)\n\n        if self.model_var is None:\n\n            prior = {'angle': numpyro.sample('angle', dist.Uniform(-jnp.pi/2, jnp.pi/2)),\n                     'eccentricity': numpyro.sample('eccentricity', dist.Uniform(0., 0.99)),\n                     'x_c': numpyro.sample('x_c', dist.Normal(0., 0.5)),\n                     'y_c': numpyro.sample('y_c', dist.Normal(0., 0.5)),\n                     'log_bkg': numpyro.sample('log_bkg', dist.Uniform(-10., -4.)),\n                     'log_ne2': numpyro.sample('log_ne2', dist.Uniform(-8., -3.)),\n                     'log_r_c': numpyro.sample('log_r_c', dist.Uniform(-2., 0.)),\n                     'log_r_s': numpyro.sample('log_r_s', dist.Uniform(-1., 1.)),\n                     'beta': numpyro.sample('beta', dist.Uniform(0., 5.)),\n                     'epsilon': numpyro.sample('epsilon', dist.Uniform(0., 5.))}\n\n        if self.model_var == 'beta':\n\n            prior = {'angle': numpyro.sample('angle', dist.TruncatedNormal(loc=angle,\n                                                                           scale=0.2,\n                                                                           low=-jnp.pi/2+angle,\n                                                                           high=jnp.pi/2+angle)),\n\n                     'eccentricity': numpyro.sample('eccentricity', dist.TruncatedNormal(\n                                                                           loc=angle,\n                                                                           scale=0.2,\n                                                                           low=0,\n                                                                           high=0.9)),\n                     'x_c': numpyro.sample('x_c', dist.Normal(0., 0.2)),\n                     'y_c': numpyro.sample('y_c', dist.Normal(0., 0.2)),\n                     'log_bkg': numpyro.sample('log_bkg', dist.Uniform(-10., -4.)),\n                     'log_e_0': numpyro.sample('log_e_0', dist.Uniform(-7., 0.)),\n                     'log_r_c': numpyro.sample('log_r_c', dist.Uniform(-4., 1.)),\n                     'beta': numpyro.sample('beta', dist.Uniform(0., 5.))}\n\n        if self.model_var == 'circ':\n\n            prior = {'angle': jnp.array(0.),\n                     'eccentricity': jnp.array(0.),\n                     'x_c': numpyro.sample('x_c', dist.Normal(0., 0.2)),\n                     'y_c': numpyro.sample('y_c', dist.Normal(0., 0.2)),\n                     'log_bkg': numpyro.sample('log_bkg', dist.Uniform(-10., -4.)),\n                     'log_e_0': numpyro.sample('log_e_0', dist.Uniform(-7., 0.)),\n                     'log_r_c': numpyro.sample('log_r_c', dist.Uniform(-4., 1.)),\n                     'beta': numpyro.sample('beta', dist.Uniform(0., 5.))}\n\n        return prior\n\n    def model(self):\n        \"\"\"\n        The numpyro model which is used in the fitting routine.\n        \"\"\"\n\n        params = set_params(self.counts.init(None), self.prior)\n\n        numpyro.sample('likelihood',\n                       dist.Poisson(self.counts.apply(params)),\n                       obs=jnp.array(self.cluster.img, dtype=jnp.float32))\n\n    def fit(self) -&gt; az.InferenceData:\n        \"\"\"\n        Perform the fitting routine.\n\n        Returns:\n            An az.InferenceData object containing the fit results.\n        \"\"\"\n\n        if self.ref_params is not None:\n\n            kernel = BarkerMH(self.model,\n                          #max_tree_depth=self.max_tree_depth,\n                          init_strategy=init_to_value(values=self.ref_params),\n                        )\n                          #dense_mass=True,\n                          #target_accept_prob=0.95)\n\n        else :\n\n            kernel = BarkerMH(self.model)\n              #max_tree_depth=self.max_tree_depth,\n              #dense_mass=True,\n              #target_accept_prob=0.95)\n\n        posterior = MCMC(kernel, **self.mcmc_config)\n\n        key = random.split(rng_key(), 4)\n        posterior.run(key[0])\n\n        posterior_samples = posterior.get_samples()\n        posterior_predictive = Predictive(self.model, posterior_samples)(key[1])\n        prior = Predictive(self.model, num_samples=100000)(key[2])\n\n        inference_data = az.from_numpyro(posterior, prior=prior, posterior_predictive=posterior_predictive)\n\n        return inference_data\n</code></pre>"},{"location":"references/fitting/#xsb_fluc.fitting.mean_model.MeanModelFitter.prior","title":"<code>prior</code>  <code>property</code>","text":"<p>Default priors distributions.</p>"},{"location":"references/fitting/#xsb_fluc.fitting.mean_model.MeanModelFitter.__init__","title":"<code>__init__(cluster, n_samples=1000, n_warmup=1000, n_chains=1, model=None, max_tree_depth=10, ref_params=None)</code>","text":"<p>Constructor for the MeanModelFitter which fit the mean model using MCMC</p> <p>Parameters:</p> Name Type Description Default <code>cluster</code> <code>Cluster</code> <p>the cluster object which will be fitted</p> required <code>n_samples</code> <code>int</code> <p>the number of samples</p> <code>1000</code> <code>n_warmup</code> <code>int</code> <p>the number of warmup samples</p> <code>1000</code> <code>n_chains</code> <code>int</code> <p>the number of chains</p> <code>1</code> <code>model</code> <code>Literal[None, 'beta', 'circ']</code> <p>the model to be fitted. Leave None to use the best.</p> <code>None</code> <code>max_tree_depth</code> <code>int</code> <p>the maximum recursion depth of the MCMC. Lower to 7 or 5 if too slow.</p> <code>10</code> <code>ref_params</code> <code>dict</code> <p>the parameters where the chain should be started.</p> <code>None</code> Source code in <code>src/xsb_fluc/fitting/mean_model.py</code> <pre><code>def __init__(self,\n             cluster: Cluster,\n             n_samples: int = 1000,\n             n_warmup: int = 1000,\n             n_chains: int = 1,\n             model: Literal[None, 'beta', 'circ'] = None,\n             max_tree_depth: int = 10,\n             ref_params=None):\n\n    \"\"\"\n    Constructor for the MeanModelFitter which fit the mean model using MCMC\n\n    Parameters:\n        cluster (Cluster): the cluster object which will be fitted\n        n_samples (int): the number of samples\n        n_warmup (int): the number of warmup samples\n        n_chains (int): the number of chains\n        model (Literal[None, 'beta', 'circ']): the model to be fitted. Leave None to use the best.\n        max_tree_depth (int): the maximum recursion depth of the MCMC. Lower to 7 or 5 if too slow.\n        ref_params (dict): the parameters where the chain should be started.\n    \"\"\"\n\n    self.cluster = cluster\n    self.model_var = model\n    self.ref_params = ref_params\n    self.max_tree_depth = max_tree_depth\n\n    if self.model_var == 'beta' or self.model_var == 'circ':\n\n        self.counts = hk.without_apply_rng(hk.transform(lambda: MockXrayCountsBetaModel(self.cluster)()))\n\n    else:\n\n        self.counts = hk.without_apply_rng(hk.transform(lambda: MockXrayCounts(self.cluster)()))\n\n    self.mcmc_config = {'num_samples': n_samples,\n                        'num_warmup': n_warmup,\n                        'num_chains': n_chains,\n                        'progress_bar': True}\n</code></pre>"},{"location":"references/fitting/#xsb_fluc.fitting.mean_model.MeanModelFitter.fit","title":"<code>fit()</code>","text":"<p>Perform the fitting routine.</p> <p>Returns:</p> Type Description <code>InferenceData</code> <p>An az.InferenceData object containing the fit results.</p> Source code in <code>src/xsb_fluc/fitting/mean_model.py</code> <pre><code>def fit(self) -&gt; az.InferenceData:\n    \"\"\"\n    Perform the fitting routine.\n\n    Returns:\n        An az.InferenceData object containing the fit results.\n    \"\"\"\n\n    if self.ref_params is not None:\n\n        kernel = BarkerMH(self.model,\n                      #max_tree_depth=self.max_tree_depth,\n                      init_strategy=init_to_value(values=self.ref_params),\n                    )\n                      #dense_mass=True,\n                      #target_accept_prob=0.95)\n\n    else :\n\n        kernel = BarkerMH(self.model)\n          #max_tree_depth=self.max_tree_depth,\n          #dense_mass=True,\n          #target_accept_prob=0.95)\n\n    posterior = MCMC(kernel, **self.mcmc_config)\n\n    key = random.split(rng_key(), 4)\n    posterior.run(key[0])\n\n    posterior_samples = posterior.get_samples()\n    posterior_predictive = Predictive(self.model, posterior_samples)(key[1])\n    prior = Predictive(self.model, num_samples=100000)(key[2])\n\n    inference_data = az.from_numpyro(posterior, prior=prior, posterior_predictive=posterior_predictive)\n\n    return inference_data\n</code></pre>"},{"location":"references/fitting/#xsb_fluc.fitting.mean_model.MeanModelFitter.model","title":"<code>model()</code>","text":"<p>The numpyro model which is used in the fitting routine.</p> Source code in <code>src/xsb_fluc/fitting/mean_model.py</code> <pre><code>def model(self):\n    \"\"\"\n    The numpyro model which is used in the fitting routine.\n    \"\"\"\n\n    params = set_params(self.counts.init(None), self.prior)\n\n    numpyro.sample('likelihood',\n                   dist.Poisson(self.counts.apply(params)),\n                   obs=jnp.array(self.cluster.img, dtype=jnp.float32))\n</code></pre>"},{"location":"references/physics/","title":"physics","text":""},{"location":"references/physics/#xsb_fluc.physics.density","title":"<code>xsb_fluc.physics.density</code>","text":"<p>Python module containing models for the density profile of the ICM.</p>"},{"location":"references/physics/#xsb_fluc.physics.density.BetaModel","title":"<code>BetaModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>Density model which use a beta-model formula</p> \\[n_{e}^2(r) = n_{e,0}^2 \\left( 1 + \\left( \\frac{r}{r_{c}} \\right)^{2} \\right)^{-3\\beta}\\] Source code in <code>src/xsb_fluc/physics/density.py</code> <pre><code>class BetaModel(hk.Module):\n    r\"\"\"Density model which use a beta-model formula\n\n    $$n_{e}^2(r) = n_{e,0}^2 \\left( 1 + \\left( \\frac{r}{r_{c}} \\right)^{2} \\right)^{-3\\beta}$$\n    \"\"\"\n    def __init__(self):\n        super(BetaModel, self).__init__()\n\n    def __call__(self, r):\n        \"\"\"Compute the density function for a given radius.\n\n        Parameters:\n            r (jnp.array): Radius to compute the density function in R500 units\n\n        Returns:\n            (jnp.array): Density function evaluated at the given radius in cm$^{-6}$\n        \"\"\"\n        log_ne2 = hk.get_parameter(\"log_ne2\", [], init=Constant(-3.))\n        log_r_c = hk.get_parameter(\"log_r_c\", [], init=Constant(-1))\n        beta = hk.get_parameter(\"beta\", [], init=Constant(2/3))\n\n        ne2 = 10 ** log_ne2\n        r_c = 10 ** log_r_c\n\n        term1 = (1. + (r / r_c) ** 2) ** (-3 * beta)\n\n        return ne2 * term1\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.density.BetaModel.__call__","title":"<code>__call__(r)</code>","text":"<p>Compute the density function for a given radius.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>array</code> <p>Radius to compute the density function in R500 units</p> required <p>Returns:</p> Type Description <code>array</code> <p>Density function evaluated at the given radius in cm\\(^{-6}\\)</p> Source code in <code>src/xsb_fluc/physics/density.py</code> <pre><code>def __call__(self, r):\n    \"\"\"Compute the density function for a given radius.\n\n    Parameters:\n        r (jnp.array): Radius to compute the density function in R500 units\n\n    Returns:\n        (jnp.array): Density function evaluated at the given radius in cm$^{-6}$\n    \"\"\"\n    log_ne2 = hk.get_parameter(\"log_ne2\", [], init=Constant(-3.))\n    log_r_c = hk.get_parameter(\"log_r_c\", [], init=Constant(-1))\n    beta = hk.get_parameter(\"beta\", [], init=Constant(2/3))\n\n    ne2 = 10 ** log_ne2\n    r_c = 10 ** log_r_c\n\n    term1 = (1. + (r / r_c) ** 2) ** (-3 * beta)\n\n    return ne2 * term1\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.density.CleanVikhlininModel","title":"<code>CleanVikhlininModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>Density model which use a modified Vikhlinin functional form, with alpha fixed to 0 and gamma to 3</p> \\[n_{e}^2(r) = n_{e,0}^2 \\left( 1 + \\left( \\frac{r}{r_{c}} \\right)^{2} \\right)^{-3\\beta} \\left(1+\\left( \\frac{r}{r_{c}} \\right)^{\\gamma} \\right)^{-\\frac{\\epsilon}{\\gamma}}\\] Source code in <code>src/xsb_fluc/physics/density.py</code> <pre><code>class CleanVikhlininModel(hk.Module):\n    r\"\"\"\n    Density model which use a modified Vikhlinin functional form, with alpha fixed to 0 and gamma to 3\n\n    $$n_{e}^2(r) = n_{e,0}^2 \\left( 1 + \\left( \\frac{r}{r_{c}} \\right)^{2} \\right)^{-3\\beta} \\left(1+\\left( \\frac{r}{r_{c}} \\right)^{\\gamma} \\right)^{-\\frac{\\epsilon}{\\gamma}}$$\n    \"\"\"\n\n    def __init__(self):\n        super(CleanVikhlininModel, self).__init__()\n\n    def __call__(self, r: jnp.array) -&gt; jnp.array:\n        \"\"\"Compute the density function for a given radius.\n\n        Parameters:\n            r (jnp.array): Radius to compute the density function in R500 units\n\n        Returns:\n            (jnp.array): Density function evaluated at the given radius in cm$^{-6}$\n        \"\"\"\n        log_ne2 = hk.get_parameter(\"log_ne2\", [], init=Constant(-3.))\n        log_r_c = hk.get_parameter(\"log_r_c\", [], init=Constant(-1.))\n        log_r_s = hk.get_parameter(\"log_r_s\", [], init=Constant(-0.1))\n        beta = hk.get_parameter(\"beta\", [], init=Constant(0.6))\n        epsilon = hk.get_parameter(\"epsilon\", [], init=Constant(3.))\n\n        gamma = 3.\n\n        ne2 = 10 ** log_ne2\n        r_c = 10 ** log_r_c\n        r_s = 10 ** log_r_s\n\n        term1 = (1. + (r / r_c) ** 2) ** (-3 * beta)\n        term2 = (1. + (r / r_s) ** gamma) ** (-epsilon / gamma)\n\n        return ne2 * term1 * term2\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.density.CleanVikhlininModel.__call__","title":"<code>__call__(r)</code>","text":"<p>Compute the density function for a given radius.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>array</code> <p>Radius to compute the density function in R500 units</p> required <p>Returns:</p> Type Description <code>array</code> <p>Density function evaluated at the given radius in cm\\(^{-6}\\)</p> Source code in <code>src/xsb_fluc/physics/density.py</code> <pre><code>def __call__(self, r: jnp.array) -&gt; jnp.array:\n    \"\"\"Compute the density function for a given radius.\n\n    Parameters:\n        r (jnp.array): Radius to compute the density function in R500 units\n\n    Returns:\n        (jnp.array): Density function evaluated at the given radius in cm$^{-6}$\n    \"\"\"\n    log_ne2 = hk.get_parameter(\"log_ne2\", [], init=Constant(-3.))\n    log_r_c = hk.get_parameter(\"log_r_c\", [], init=Constant(-1.))\n    log_r_s = hk.get_parameter(\"log_r_s\", [], init=Constant(-0.1))\n    beta = hk.get_parameter(\"beta\", [], init=Constant(0.6))\n    epsilon = hk.get_parameter(\"epsilon\", [], init=Constant(3.))\n\n    gamma = 3.\n\n    ne2 = 10 ** log_ne2\n    r_c = 10 ** log_r_c\n    r_s = 10 ** log_r_s\n\n    term1 = (1. + (r / r_c) ** 2) ** (-3 * beta)\n    term2 = (1. + (r / r_s) ** gamma) ** (-epsilon / gamma)\n\n    return ne2 * term1 * term2\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.temperature","title":"<code>xsb_fluc.physics.temperature</code>","text":"<p>Python module containing models for the temperature profile of the ICM.</p>"},{"location":"references/physics/#xsb_fluc.physics.temperature.GhirardiniModel","title":"<code>GhirardiniModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>Universal temperature profile as defined in Ghirardini 2018+ in the X-COP cluster sample</p> Source code in <code>src/xsb_fluc/physics/temperature.py</code> <pre><code>class GhirardiniModel(hk.Module):\n    \"\"\"\n    Universal temperature profile as defined in Ghirardini 2018+ in the X-COP cluster sample\n    \"\"\"\n\n    def __init__(self):\n        super(GhirardiniModel, self).__init__()\n\n    def __call__(self, r):\n        \"\"\"\n        Compute the temperature function for a given radius.\n\n        Parameters:\n            r (jnp.array): Radius to compute the temperature in $R_{500}$ units\n\n        Returns:\n            (jnp.array): Temperature function evaluated at the given radius in keV\n        \"\"\"\n\n        T0 = 1.21\n        rcool = jnp.exp(-2.78)\n        rt = 0.34\n        TmT0 = 0.5\n        acool = 1.03\n        c2 = 0.27\n\n        T500 = 7.  # keV\n\n        term1 = (TmT0 + (r / rcool) ** acool)\n        term2 = (1 + (r / rcool) ** acool) * (1 + (r / rt) ** 2) ** c2\n\n        return T500 * T0 * term1 / term2\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.temperature.GhirardiniModel.__call__","title":"<code>__call__(r)</code>","text":"<p>Compute the temperature function for a given radius.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>array</code> <p>Radius to compute the temperature in \\(R_{500}\\) units</p> required <p>Returns:</p> Type Description <code>array</code> <p>Temperature function evaluated at the given radius in keV</p> Source code in <code>src/xsb_fluc/physics/temperature.py</code> <pre><code>def __call__(self, r):\n    \"\"\"\n    Compute the temperature function for a given radius.\n\n    Parameters:\n        r (jnp.array): Radius to compute the temperature in $R_{500}$ units\n\n    Returns:\n        (jnp.array): Temperature function evaluated at the given radius in keV\n    \"\"\"\n\n    T0 = 1.21\n    rcool = jnp.exp(-2.78)\n    rt = 0.34\n    TmT0 = 0.5\n    acool = 1.03\n    c2 = 0.27\n\n    T500 = 7.  # keV\n\n    term1 = (TmT0 + (r / rcool) ** acool)\n    term2 = (1 + (r / rcool) ** acool) * (1 + (r / rt) ** 2) ** c2\n\n    return T500 * T0 * term1 / term2\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.cooling","title":"<code>xsb_fluc.physics.cooling</code>","text":"<p>Python module containing structures to compute the cooling function approximation for the ICM.</p>"},{"location":"references/physics/#xsb_fluc.physics.cooling.CoolingFunctionGrid","title":"<code>CoolingFunctionGrid</code>","text":"Source code in <code>src/xsb_fluc/physics/cooling.py</code> <pre><code>class CoolingFunctionGrid:\n\n    def __init__(self, redshift=0.01, n_points=20, kT_span=(1., 10.), nH_span=(9e19, 2e21)):\n        \"\"\"\n        Awfully coded class to compute the cooling function grid for a given redshift.\n        The grid is saved in a .npy file in the results folder. XSPEC is not needed if the\n        grid is already computed. Else it will be computed using XSPEC.\n\n        \"\"\"\n\n        self.redshift = round(redshift, 5)\n        self.n_points = n_points\n        self.kT_span = kT_span\n        self.nH_span = nH_span\n\n        pars = (self.redshift, n_points, *kT_span, *nH_span)\n\n        self.kT, self.nH = np.meshgrid(np.linspace(*kT_span, n_points),\n                                       np.geomspace(*nH_span, n_points),\n                                       indexing='ij')\n\n        cooling_path = os.path.join(config.RESULTS_PATH, 'cooling_database', f'{pars}.npy')\n\n        if not os.path.exists(cooling_path):\n\n            print('Cooling grid not found! Computing with XSPEC')\n\n            from .countrate import PHabsAPEC\n\n            phabs = PHabsAPEC()\n\n            abundance = 0.3\n            norm = 1.\n            countrate = phabs.countrate(self.nH / 1e22, self.kT, abundance, float(self.redshift), norm)\n\n            # XSPEC norm factor for an apec model\n            dc = FlatLambdaCDM(70, 0.3).comoving_distance(redshift).to(u.Mpc)\n            factor = 1e-14 / (4 * np.pi * dc ** 2) / 1.17\n\n            # Units of the countrate over units of the norm of APEC model\n            cooling = factor * countrate * (u.count * u.s ** (-1) * u.cm ** 5)\n\n            # Conversion to the best unit for Lambda * ne^2\n            self.cooling = (cooling.to(u.count * u.cm ** 6 / u.kpc ** 3 / u.s)).value\n            np.save(cooling_path, self.cooling)\n\n        else:\n\n            self.cooling = np.load(cooling_path)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.cooling.CoolingFunctionGrid.__init__","title":"<code>__init__(redshift=0.01, n_points=20, kT_span=(1.0, 10.0), nH_span=(9e+19, 2e+21))</code>","text":"<p>Awfully coded class to compute the cooling function grid for a given redshift. The grid is saved in a .npy file in the results folder. XSPEC is not needed if the grid is already computed. Else it will be computed using XSPEC.</p> Source code in <code>src/xsb_fluc/physics/cooling.py</code> <pre><code>def __init__(self, redshift=0.01, n_points=20, kT_span=(1., 10.), nH_span=(9e19, 2e21)):\n    \"\"\"\n    Awfully coded class to compute the cooling function grid for a given redshift.\n    The grid is saved in a .npy file in the results folder. XSPEC is not needed if the\n    grid is already computed. Else it will be computed using XSPEC.\n\n    \"\"\"\n\n    self.redshift = round(redshift, 5)\n    self.n_points = n_points\n    self.kT_span = kT_span\n    self.nH_span = nH_span\n\n    pars = (self.redshift, n_points, *kT_span, *nH_span)\n\n    self.kT, self.nH = np.meshgrid(np.linspace(*kT_span, n_points),\n                                   np.geomspace(*nH_span, n_points),\n                                   indexing='ij')\n\n    cooling_path = os.path.join(config.RESULTS_PATH, 'cooling_database', f'{pars}.npy')\n\n    if not os.path.exists(cooling_path):\n\n        print('Cooling grid not found! Computing with XSPEC')\n\n        from .countrate import PHabsAPEC\n\n        phabs = PHabsAPEC()\n\n        abundance = 0.3\n        norm = 1.\n        countrate = phabs.countrate(self.nH / 1e22, self.kT, abundance, float(self.redshift), norm)\n\n        # XSPEC norm factor for an apec model\n        dc = FlatLambdaCDM(70, 0.3).comoving_distance(redshift).to(u.Mpc)\n        factor = 1e-14 / (4 * np.pi * dc ** 2) / 1.17\n\n        # Units of the countrate over units of the norm of APEC model\n        cooling = factor * countrate * (u.count * u.s ** (-1) * u.cm ** 5)\n\n        # Conversion to the best unit for Lambda * ne^2\n        self.cooling = (cooling.to(u.count * u.cm ** 6 / u.kpc ** 3 / u.s)).value\n        np.save(cooling_path, self.cooling)\n\n    else:\n\n        self.cooling = np.load(cooling_path)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.cooling.CoolingFunctionModel","title":"<code>CoolingFunctionModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>Cooling function model using a grid of precomputed cooling function. It is fitted to the grid using a least square method on the fly. The model is given by the following formula:</p> \\[\\Psi(N_H, T) \\simeq \\Lambda_0 e^{- N_H \\sigma} \\left( \\frac{T}{T_{\\text{break}}}\\right)^{-\\alpha_{1}}\\left(\\frac{1}{2} + \\frac{1}{2}\\left(\\frac{T}{T_{\\text{break}}}\\right)^{1/\\Delta}\\right)^{(\\alpha_1 - \\alpha_2)\\Delta}\\] <p>Note</p> <p>\\(\\Psi(N_H, T)\\) here is different from \\(\\Lambda(T)\\) as it includes the instrumental convolution</p> Source code in <code>src/xsb_fluc/physics/cooling.py</code> <pre><code>class CoolingFunctionModel(hk.Module):\n    r\"\"\"\n    Cooling function model using a grid of precomputed cooling function. It is fitted to the grid using\n    a least square method on the fly. The model is given by the following formula:\n\n    $$\\Psi(N_H, T) \\simeq \\Lambda_0 e^{- N_H \\sigma} \\left( \\frac{T}{T_{\\text{break}}}\\right)^{-\\alpha_{1}}\\left(\\frac{1}{2} + \\frac{1}{2}\\left(\\frac{T}{T_{\\text{break}}}\\right)^{1/\\Delta}\\right)^{(\\alpha_1 - \\alpha_2)\\Delta}$$\n\n    !!! note\n        $\\Psi(N_H, T)$ here is different from $\\Lambda(T)$ as it includes the instrumental convolution\n    \"\"\"\n\n    def __init__(self, coolingFunctionGrid):\n        super(CoolingFunctionModel, self).__init__()\n        self.grid = coolingFunctionGrid\n        # Norm, sigma, kTbreak, alpha1, alpha2, delta\n        X = jnp.array([0.01, 3., 1.65, 1.7, 0.14, 0.13])\n\n        self.res = minimize(self.fitness, X, method=\"BFGS\", tol=1e-15)\n        self.pars = self.res.x\n\n    def kT_dependency(self, kT, kT_break, alpha1, alpha2, delta):\n        t = (kT / kT_break)\n\n        return t ** (-alpha1) * (1 / 2 * (1 + t ** (1 / delta))) ** ((alpha1 - alpha2) * delta)\n\n    def nH_dependency(self, nH, sigma):\n        return jnp.exp(-nH / 1e22 * sigma)\n\n    def model(self, nH, kT, pars):\n        return pars[0] * self.nH_dependency(nH, pars[1]) * self.kT_dependency(kT, *pars[2:])\n\n    def __call__(self, nH, kT):\n        return self.model(nH, kT, self.pars)\n\n    def fitness(self, pars):\n        lsq = (self.grid.cooling - self.model(self.grid.nH, self.grid.kT, pars)) ** 2\n\n        return jnp.sum(lsq / self.grid.cooling ** 2) ** 1 / 2\n\n    @property\n    def residual(self):\n        lsq = (self.grid.cooling - self.model(self.grid.nH, self.grid.kT, self.pars)) ** 2\n\n        return lsq ** (1 / 2) / self.grid.cooling\n\n    def plot_residual(self):\n        plt.figure()\n        plt.contourf(self.grid.kT, self.grid.nH, self.residual)\n        plt.colorbar()\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.emissivity","title":"<code>xsb_fluc.physics.emissivity</code>","text":""},{"location":"references/physics/#xsb_fluc.physics.emissivity.XrayEmissivity","title":"<code>XrayEmissivity</code>","text":"<p>               Bases: <code>Module</code></p> <p>3D Xray emissivity build with temperature, cooling function, density model. It depends on the redshift of the cluster, since the cooling function is precomputed using XSPEC. The default models are the ones used in the papers i.e. Vikhlinin for density, Ghirardini for temperature and the interpolated cooling function.</p> Source code in <code>src/xsb_fluc/physics/emissivity.py</code> <pre><code>class XrayEmissivity(hk.Module):\n    \"\"\"\n    3D Xray emissivity build with temperature, cooling function, density model.\n    It depends on the redshift of the cluster, since the cooling function is precomputed using XSPEC.\n    The default models are the ones used in the papers i.e. Vikhlinin for density, Ghirardini for temperature\n    and the interpolated cooling function.\n    \"\"\"\n    def __init__(self, redshift):\n        super(XrayEmissivity, self).__init__()\n        self.squared_density = CleanVikhlininModel()\n        self.temperature = GhirardiniModel()\n        self.cooling_function = CoolingFunctionModel(CoolingFunctionGrid(n_points=10, redshift=redshift))\n\n    @classmethod\n    def from_data(cls, data: \"Cluster\"):\n        \"\"\"\n        Create an emissivity model from a `Cluster` object\n        \"\"\"\n        return cls(data.z)\n\n    def __call__(self, r, nH):\n        \"\"\"\n        Compute the emissivity at a given radius, including $N_H$ absorption.\n\n        Parameters:\n            r (jnp.array): radius in units of $R_{500}$\n            nH (jnp.array): Hydrogen density in cm$^{-2}$ in the line of sight corresponding to the radius r\n        \"\"\"\n        return self.cooling_function(nH, self.temperature(r)) * self.squared_density(r)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.emissivity.XrayEmissivity.__call__","title":"<code>__call__(r, nH)</code>","text":"<p>Compute the emissivity at a given radius, including \\(N_H\\) absorption.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>array</code> <p>radius in units of \\(R_{500}\\)</p> required <code>nH</code> <code>array</code> <p>Hydrogen density in cm\\(^{-2}\\) in the line of sight corresponding to the radius r</p> required Source code in <code>src/xsb_fluc/physics/emissivity.py</code> <pre><code>def __call__(self, r, nH):\n    \"\"\"\n    Compute the emissivity at a given radius, including $N_H$ absorption.\n\n    Parameters:\n        r (jnp.array): radius in units of $R_{500}$\n        nH (jnp.array): Hydrogen density in cm$^{-2}$ in the line of sight corresponding to the radius r\n    \"\"\"\n    return self.cooling_function(nH, self.temperature(r)) * self.squared_density(r)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.emissivity.XrayEmissivity.from_data","title":"<code>from_data(data)</code>  <code>classmethod</code>","text":"<p>Create an emissivity model from a <code>Cluster</code> object</p> Source code in <code>src/xsb_fluc/physics/emissivity.py</code> <pre><code>@classmethod\ndef from_data(cls, data: \"Cluster\"):\n    \"\"\"\n    Create an emissivity model from a `Cluster` object\n    \"\"\"\n    return cls(data.z)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.projection","title":"<code>xsb_fluc.physics.projection</code>","text":""},{"location":"references/physics/#xsb_fluc.physics.projection.AbelTransform","title":"<code>AbelTransform</code>","text":"<p>               Bases: <code>Module</code></p> <p>Projection tool for 3D models. Relies on double exponential quadrature.</p> \\[\\text{AbelTransform}\\left\\{ f\\right\\}(x, y) =  \\int \\text{d}z \\, f(x, y, z)\\] <p>It uses double exponential quadrature to perform the integration.</p> <p>References :</p> <ul> <li>Takahasi and Mori (1974)</li> <li>Mori and Sugihara (2001)</li> <li>Tanh-sinh quadrature from wikipedia</li> </ul> Source code in <code>src/xsb_fluc/physics/projection.py</code> <pre><code>class AbelTransform(hk.Module):\n    r\"\"\"\n    Projection tool for 3D models. Relies on double exponential quadrature.\n\n    $$\\text{AbelTransform}\\left\\{ f\\right\\}(x, y) =  \\int \\text{d}z \\, f(x, y, z)$$\n\n    It uses double exponential quadrature to perform the integration.\n\n    References :\n\n    * [Takahasi and Mori (1974)](https://ems.press/journals/prims/articles/2686)\n    * [Mori and Sugihara (2001)](https://doi.org/10.1016/S0377-0427(00)00501-X)\n    * [Tanh-sinh quadrature](https://en.wikipedia.org/wiki/Tanh-sinh_quadrature) from wikipedia\n\n    \"\"\"\n\n    def __init__(self, model:\"hk.Module\", n_points=71):\n        \"\"\"\n        Take a model and project it along the line of sight.\n\n        Parameters:\n            model (hk.Module): model to project\n            n_points (int): number of points to use for the quadrature\n        \"\"\"\n        super(AbelTransform, self).__init__()\n        self.model = model\n        self.n = n_points\n        self.t = jnp.linspace(-3, 3, self.n)\n\n    def __call__(self, r, *args):\n\n        r = jnp.asarray(r)[..., None]\n        t = self.t[None, :]\n        x = phi(t)\n        dx = dphi(t)\n\n        return 2 * jnp.trapz(self.model(jnp.sqrt(r ** 2 + x ** 2), *args) * dx, x=t, axis=-1)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.projection.AbelTransform.__init__","title":"<code>__init__(model, n_points=71)</code>","text":"<p>Take a model and project it along the line of sight.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>model to project</p> required <code>n_points</code> <code>int</code> <p>number of points to use for the quadrature</p> <code>71</code> Source code in <code>src/xsb_fluc/physics/projection.py</code> <pre><code>def __init__(self, model:\"hk.Module\", n_points=71):\n    \"\"\"\n    Take a model and project it along the line of sight.\n\n    Parameters:\n        model (hk.Module): model to project\n        n_points (int): number of points to use for the quadrature\n    \"\"\"\n    super(AbelTransform, self).__init__()\n    self.model = model\n    self.n = n_points\n    self.t = jnp.linspace(-3, 3, self.n)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.surface_brightness","title":"<code>xsb_fluc.physics.surface_brightness</code>","text":""},{"location":"references/physics/#xsb_fluc.physics.surface_brightness.XraySurfaceBrightness","title":"<code>XraySurfaceBrightness</code>","text":"<p>               Bases: <code>Module</code></p> <p>Xray surface brightness model from 3D emissivity</p> Source code in <code>src/xsb_fluc/physics/surface_brightness.py</code> <pre><code>class XraySurfaceBrightness(hk.Module):\n    \"\"\"\n    Xray surface brightness model from 3D emissivity\n    \"\"\"\n\n    def __init__(self, redshift, r_500):\n        super(XraySurfaceBrightness, self).__init__()\n        self.emissivity = XrayEmissivity(redshift)\n        self.surface_brightness = AbelTransform(self.emissivity)\n        self.r_500 = r_500.to(u.kpc).value\n\n    @classmethod\n    def from_data(cls, data: \"Cluster\"):\n        \"\"\"\n        Create a surface brightness model from a `Cluster` object\n        \"\"\"\n\n        return cls(data.z, data.r_500)\n\n    def __call__(self, r, nh):\n        log_bkg = hk.get_parameter(\"log_bkg\", [], init=Constant(-5.))\n\n        # As we integrate toward the l.o.s in r_500 units,\n        # the surface brightness must be rescaled to be in good units\n        return self.surface_brightness(r, nh[..., None]) * self.r_500 + 10 ** log_bkg\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.surface_brightness.XraySurfaceBrightness.from_data","title":"<code>from_data(data)</code>  <code>classmethod</code>","text":"<p>Create a surface brightness model from a <code>Cluster</code> object</p> Source code in <code>src/xsb_fluc/physics/surface_brightness.py</code> <pre><code>@classmethod\ndef from_data(cls, data: \"Cluster\"):\n    \"\"\"\n    Create a surface brightness model from a `Cluster` object\n    \"\"\"\n\n    return cls(data.z, data.r_500)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.surface_brightness.XraySurfaceBrightnessBetaModel","title":"<code>XraySurfaceBrightnessBetaModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>Xray surface brightness from a 2D surface brightness Beta-model</p> Source code in <code>src/xsb_fluc/physics/surface_brightness.py</code> <pre><code>class XraySurfaceBrightnessBetaModel(hk.Module):\n    \"\"\"\n    Xray surface brightness from a 2D surface brightness Beta-model\n    \"\"\"\n\n    def __call__(self, r):\n        log_bkg = hk.get_parameter(\"log_bkg\", [], init=Constant(-5.))\n        log_e_0 = hk.get_parameter(\"log_e_0\", [], init=Constant(-4))\n        log_r_c = hk.get_parameter(\"log_r_c\", [], init=Constant(-1.))\n        beta = hk.get_parameter(\"beta\", [], init=Constant(2 / 3))\n\n        e_0 = 10**log_e_0\n        r_c = 10**log_r_c\n\n        u_beta = jnp.sqrt(jnp.pi)*jnp.exp(gammaln(3*beta - 1/2)-gammaln(3*beta))\n\n        return u_beta*e_0*(1+(r/r_c)**2)**(1/2-3*beta) + 10 ** log_bkg\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.ellipse","title":"<code>xsb_fluc.physics.ellipse</code>","text":"<p>Python module containing models for the ellipticity of projected surface brightness.</p>"},{"location":"references/physics/#xsb_fluc.physics.ellipse.EllipseRadius","title":"<code>EllipseRadius</code>","text":"<p>               Bases: <code>Module</code></p> <p>Include ellipticity in 2D radius maps</p> Source code in <code>src/xsb_fluc/physics/ellipse.py</code> <pre><code>class EllipseRadius(hk.Module):\n    \"\"\"\n    Include ellipticity in 2D radius maps\n    \"\"\"\n\n    def __init__(self, x_c, y_c, pixel_size):\n        super(EllipseRadius, self).__init__()\n        self.x_c_init = x_c\n        self.y_c_init = y_c\n        self.pixel_size = pixel_size\n\n    @classmethod\n    def from_data(cls, data: \"Cluster\"):\n        \"\"\"\n        Build the ellipticity model from a `Cluster` object.\n        \"\"\"\n\n        pixel_size = (data.kpc_per_pixel/data.r_500).to(1 / u.pix).value\n\n        return cls(data.x_c, data.y_c, pixel_size)\n\n    def __call__(self, x_ref, y_ref):\n        \"\"\"\n        Compute the elliptical radius for a given position.\n\n        Returns:\n            (jnp.array): Elliptical radius in unit of $R_{500}$\n        \"\"\"\n        angle = hk.get_parameter(\"angle\", [], init=Constant(0.))\n        e = hk.get_parameter(\"eccentricity\", [], init=Constant(0.))\n        x_c = self.x_c_init*(1+hk.get_parameter(\"x_c\", [], init=Constant(0.)))\n        y_c = self.y_c_init*(1+hk.get_parameter(\"y_c\", [], init=Constant(0.)))\n\n        x_tilde = (x_ref-x_c)*jnp.cos(angle) - (y_ref-y_c)*jnp.sin(angle)\n        y_tilde = (y_ref-y_c)*jnp.cos(angle) + (x_ref-x_c)*jnp.sin(angle)\n        r = jnp.sqrt(x_tilde**2*(1-e**2)**(-1/2) + y_tilde**2*(1-e**2)**(1/2))*self.pixel_size\n\n        return r\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.ellipse.EllipseRadius.__call__","title":"<code>__call__(x_ref, y_ref)</code>","text":"<p>Compute the elliptical radius for a given position.</p> <p>Returns:</p> Type Description <code>array</code> <p>Elliptical radius in unit of \\(R_{500}\\)</p> Source code in <code>src/xsb_fluc/physics/ellipse.py</code> <pre><code>def __call__(self, x_ref, y_ref):\n    \"\"\"\n    Compute the elliptical radius for a given position.\n\n    Returns:\n        (jnp.array): Elliptical radius in unit of $R_{500}$\n    \"\"\"\n    angle = hk.get_parameter(\"angle\", [], init=Constant(0.))\n    e = hk.get_parameter(\"eccentricity\", [], init=Constant(0.))\n    x_c = self.x_c_init*(1+hk.get_parameter(\"x_c\", [], init=Constant(0.)))\n    y_c = self.y_c_init*(1+hk.get_parameter(\"y_c\", [], init=Constant(0.)))\n\n    x_tilde = (x_ref-x_c)*jnp.cos(angle) - (y_ref-y_c)*jnp.sin(angle)\n    y_tilde = (y_ref-y_c)*jnp.cos(angle) + (x_ref-x_c)*jnp.sin(angle)\n    r = jnp.sqrt(x_tilde**2*(1-e**2)**(-1/2) + y_tilde**2*(1-e**2)**(1/2))*self.pixel_size\n\n    return r\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.ellipse.EllipseRadius.from_data","title":"<code>from_data(data)</code>  <code>classmethod</code>","text":"<p>Build the ellipticity model from a <code>Cluster</code> object.</p> Source code in <code>src/xsb_fluc/physics/ellipse.py</code> <pre><code>@classmethod\ndef from_data(cls, data: \"Cluster\"):\n    \"\"\"\n    Build the ellipticity model from a `Cluster` object.\n    \"\"\"\n\n    pixel_size = (data.kpc_per_pixel/data.r_500).to(1 / u.pix).value\n\n    return cls(data.x_c, data.y_c, pixel_size)\n</code></pre>"},{"location":"references/physics/#xsb_fluc.physics.turbulence","title":"<code>xsb_fluc.physics.turbulence</code>","text":""},{"location":"references/physics/#xsb_fluc.physics.turbulence.KolmogorovPowerSpectrum","title":"<code>KolmogorovPowerSpectrum</code>","text":"<p>               Bases: <code>Module</code></p> <p>Kolmogorov power spectrum</p> \\[\\mathcal{P}_{3D}(k)= \\sigma^2 \\frac{e^{-\\left(k/k_{\\text{inj}}\\right)^2} e^{-\\left(k_{\\text{dis}}/k\\right)^2} k^{-\\alpha} }{\\int 4\\pi k^2  \\, e^{-\\left(k/k_{\\text{inj}}\\right)^2} e^{-\\left(k_{\\text{dis}}/k\\right)^2} k^{-\\alpha} \\text{d} k}\\] Source code in <code>src/xsb_fluc/physics/turbulence.py</code> <pre><code>class KolmogorovPowerSpectrum(hk.Module):\n    r\"\"\"\n    Kolmogorov power spectrum\n\n    $$\\mathcal{P}_{3D}(k)= \\sigma^2 \\frac{e^{-\\left(k/k_{\\text{inj}}\\right)^2} e^{-\\left(k_{\\text{dis}}/k\\right)^2} k^{-\\alpha} }{\\int 4\\pi k^2  \\, e^{-\\left(k/k_{\\text{inj}}\\right)^2} e^{-\\left(k_{\\text{dis}}/k\\right)^2} k^{-\\alpha} \\text{d} k}$$\n    \"\"\"\n\n    def __init__(self):\n        super(KolmogorovPowerSpectrum, self).__init__()\n\n    def __call__(self, k):\n\n        log_sigma = hk.get_parameter(\"log_sigma\", [], init=Constant(-1.))\n        log_inj = hk.get_parameter(\"log_inj\", [], init=Constant(-0.3))\n        log_dis = -3.\n        alpha = hk.get_parameter(\"alpha\", [], init=Constant(11/3))\n\n        k_inj = 10 ** (-log_inj)\n        k_dis = 10 ** (-log_dis)\n\n        sigma = 10**log_sigma\n\n        k_int = jnp.geomspace(k_inj/20, k_dis*20, 1000)\n        norm = jnp.trapz(4*jnp.pi*k_int**3*jnp.exp(-(k_inj / k_int) ** 2) * jnp.exp(-(k_int/ k_dis) ** 2) * (k_int) ** (-alpha), x=jnp.log(k_int))\n        res = jnp.where(k &gt; 0, jnp.exp(-(k_inj / k) ** 2) * jnp.exp(-(k / k_dis) ** 2) * k ** (-alpha), 0.)\n\n        return sigma**2 * res / norm\n</code></pre>"},{"location":"references/simulation/","title":"simulation","text":""},{"location":"references/simulation/#xsb_fluc.simulation.grid","title":"<code>xsb_fluc.simulation.grid</code>","text":""},{"location":"references/simulation/#xsb_fluc.simulation.grid.FourierGrid3D","title":"<code>FourierGrid3D</code>","text":"<p>The equivalent of a Spatial grid in Fourier space</p> Source code in <code>src/xsb_fluc/simulation/grid.py</code> <pre><code>class FourierGrid3D:\n    \"\"\"\n    The equivalent of a Spatial grid in Fourier space\n    \"\"\"\n\n    def __init__(self, spatial_grid: SpatialGrid3D):\n        \"\"\"\n        Constructor of a FourierGrid3D object as the dual of a SpatialGrid3D\n        \"\"\"\n\n        self.kx = fft.fftfreq(len(spatial_grid.x), d=spatial_grid.x[1] - spatial_grid.x[0])\n        self.ky = fft.fftfreq(len(spatial_grid.y), d=spatial_grid.y[1] - spatial_grid.y[0])\n        self.kz = fft.rfftfreq(len(spatial_grid.z), d=spatial_grid.z[1] - spatial_grid.z[0])\n        KX, KY, KZ = jnp.meshgrid(self.kx, self.ky, self.kz, indexing='ij', sparse=True)\n        self.K = jnp.sqrt(KX ** 2 + KY ** 2 + KZ ** 2)\n\n        self.shape = self.K.shape\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.grid.FourierGrid3D.__init__","title":"<code>__init__(spatial_grid)</code>","text":"<p>Constructor of a FourierGrid3D object as the dual of a SpatialGrid3D</p> Source code in <code>src/xsb_fluc/simulation/grid.py</code> <pre><code>def __init__(self, spatial_grid: SpatialGrid3D):\n    \"\"\"\n    Constructor of a FourierGrid3D object as the dual of a SpatialGrid3D\n    \"\"\"\n\n    self.kx = fft.fftfreq(len(spatial_grid.x), d=spatial_grid.x[1] - spatial_grid.x[0])\n    self.ky = fft.fftfreq(len(spatial_grid.y), d=spatial_grid.y[1] - spatial_grid.y[0])\n    self.kz = fft.rfftfreq(len(spatial_grid.z), d=spatial_grid.z[1] - spatial_grid.z[0])\n    KX, KY, KZ = jnp.meshgrid(self.kx, self.ky, self.kz, indexing='ij', sparse=True)\n    self.K = jnp.sqrt(KX ** 2 + KY ** 2 + KZ ** 2)\n\n    self.shape = self.K.shape\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.grid.SpatialGrid3D","title":"<code>SpatialGrid3D</code>","text":"<p>Helper function to define a spatial grid to simulate a 3D cluster</p> Source code in <code>src/xsb_fluc/simulation/grid.py</code> <pre><code>class SpatialGrid3D:\n    \"\"\"\n    Helper function to define a spatial grid to simulate a 3D cluster\n    \"\"\"\n\n    def __init__(self, pixsize=2./1000., shape=(100, 100), crop_r_500=5.):\n        r\"\"\"\n        Constructor for SpatialGrid3D.\n\n        Parameters:\n            pixsize (float): Size of the pixel in $R_{500}$ units.\n            shape (tuple): Shape of the cube on the sky.\n            crop_r_500 (float): Size along the line of sight in $\\pm R_{500}$.\n        \"\"\"\n\n        self.pixsize = pixsize\n\n        x_size, y_size = shape\n        z_size = np.ceil(2*crop_r_500/pixsize).astype(int)\n\n        self.x = jnp.linspace(-self.pixsize * (x_size - 1)/2, self.pixsize * (x_size - 1)/2, x_size)\n        self.y = jnp.linspace(-self.pixsize * (y_size - 1)/2, self.pixsize * (y_size - 1)/2, y_size)\n        self.z = jnp.linspace(-self.pixsize * (z_size - 1)/2, self.pixsize * (z_size - 1)/2, z_size)\n        self.X, self.Y, self.Z = jnp.meshgrid(self.x, self.y, self.z, indexing='ij', sparse=True)\n        self.y_i, self.x_i = jnp.indices(shape)\n        self.R = jnp.sqrt(self.X**2 + self.Y**2 + self.Z**2)\n        self.shape = (x_size, y_size, z_size)\n        self.volume = np.prod(self.shape)*pixsize**3\n\n    @classmethod\n    def from_data(cls, data: Cluster, crop_r_500=5., pixsize=None):\n        \"\"\"\n        Constructor for SpatialGrid3D using a Cluster object\n\n        Parameters:\n            crop_r_500: size along the line of sight.\n            pixsize: should be None since it is read from the Cluster\n        \"\"\"\n\n        if pixsize is None:\n\n            return cls(pixsize=(data.kpc_per_pixel/data.r_500).to(1/u.pixel).value,\n                       shape = data.shape, \n                       crop_r_500=crop_r_500)\n\n        else : \n\n            return cls(pixsize=pixsize,\n                       shape = data.shape, \n                       crop_r_500=crop_r_500)\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.grid.SpatialGrid3D.__init__","title":"<code>__init__(pixsize=2.0 / 1000.0, shape=(100, 100), crop_r_500=5.0)</code>","text":"<p>Constructor for SpatialGrid3D.</p> <p>Parameters:</p> Name Type Description Default <code>pixsize</code> <code>float</code> <p>Size of the pixel in \\(R_{500}\\) units.</p> <code>2.0 / 1000.0</code> <code>shape</code> <code>tuple</code> <p>Shape of the cube on the sky.</p> <code>(100, 100)</code> <code>crop_r_500</code> <code>float</code> <p>Size along the line of sight in \\(\\pm R_{500}\\).</p> <code>5.0</code> Source code in <code>src/xsb_fluc/simulation/grid.py</code> <pre><code>def __init__(self, pixsize=2./1000., shape=(100, 100), crop_r_500=5.):\n    r\"\"\"\n    Constructor for SpatialGrid3D.\n\n    Parameters:\n        pixsize (float): Size of the pixel in $R_{500}$ units.\n        shape (tuple): Shape of the cube on the sky.\n        crop_r_500 (float): Size along the line of sight in $\\pm R_{500}$.\n    \"\"\"\n\n    self.pixsize = pixsize\n\n    x_size, y_size = shape\n    z_size = np.ceil(2*crop_r_500/pixsize).astype(int)\n\n    self.x = jnp.linspace(-self.pixsize * (x_size - 1)/2, self.pixsize * (x_size - 1)/2, x_size)\n    self.y = jnp.linspace(-self.pixsize * (y_size - 1)/2, self.pixsize * (y_size - 1)/2, y_size)\n    self.z = jnp.linspace(-self.pixsize * (z_size - 1)/2, self.pixsize * (z_size - 1)/2, z_size)\n    self.X, self.Y, self.Z = jnp.meshgrid(self.x, self.y, self.z, indexing='ij', sparse=True)\n    self.y_i, self.x_i = jnp.indices(shape)\n    self.R = jnp.sqrt(self.X**2 + self.Y**2 + self.Z**2)\n    self.shape = (x_size, y_size, z_size)\n    self.volume = np.prod(self.shape)*pixsize**3\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.grid.SpatialGrid3D.from_data","title":"<code>from_data(data, crop_r_500=5.0, pixsize=None)</code>  <code>classmethod</code>","text":"<p>Constructor for SpatialGrid3D using a Cluster object</p> <p>Parameters:</p> Name Type Description Default <code>crop_r_500</code> <p>size along the line of sight.</p> <code>5.0</code> <code>pixsize</code> <p>should be None since it is read from the Cluster</p> <code>None</code> Source code in <code>src/xsb_fluc/simulation/grid.py</code> <pre><code>@classmethod\ndef from_data(cls, data: Cluster, crop_r_500=5., pixsize=None):\n    \"\"\"\n    Constructor for SpatialGrid3D using a Cluster object\n\n    Parameters:\n        crop_r_500: size along the line of sight.\n        pixsize: should be None since it is read from the Cluster\n    \"\"\"\n\n    if pixsize is None:\n\n        return cls(pixsize=(data.kpc_per_pixel/data.r_500).to(1/u.pixel).value,\n                   shape = data.shape, \n                   crop_r_500=crop_r_500)\n\n    else : \n\n        return cls(pixsize=pixsize,\n                   shape = data.shape, \n                   crop_r_500=crop_r_500)\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.cube","title":"<code>xsb_fluc.simulation.cube</code>","text":""},{"location":"references/simulation/#xsb_fluc.simulation.cube.EmissivityCube","title":"<code>EmissivityCube</code>","text":"<p>               Bases: <code>Module</code></p> <p>Compute an emissivity cube for a given cluster. Used as a part of simulations.</p> Source code in <code>src/xsb_fluc/simulation/cube.py</code> <pre><code>class EmissivityCube(hk.Module):\n    \"\"\"\n    Compute an emissivity cube for a given cluster. Used as a part of simulations.\n    \"\"\"\n\n    def __init__(self, data: Cluster):\n        \"\"\"\n        Constructor for EmissivityCube using a Cluster object\n        \"\"\"\n\n        super(EmissivityCube, self).__init__()\n        self.emissivity = XrayEmissivity.from_data(data)\n        self.radius = EllipseRadius.from_data(data)\n        self.spatial_grid = SpatialGrid3D.from_data(data, crop_r_500=5)\n        self.nh = data.nh\n        self.x_i, self.x_j = self.spatial_grid.x_i, self.spatial_grid.y_i\n        self.Z = self.spatial_grid.Z\n\n    def __call__(self) -&gt; jax.Array:\n        \"\"\"\n        Return the emissivity cube.\n        \"\"\"\n\n        Rho = self.radius(self.x_i, self.x_j) \n        R = jnp.sqrt(Rho[..., None]**2 + self.Z**2)\n        epsilon = self.emissivity(R, self.nh[..., None])\n\n        return epsilon\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.cube.EmissivityCube.__call__","title":"<code>__call__()</code>","text":"<p>Return the emissivity cube.</p> Source code in <code>src/xsb_fluc/simulation/cube.py</code> <pre><code>def __call__(self) -&gt; jax.Array:\n    \"\"\"\n    Return the emissivity cube.\n    \"\"\"\n\n    Rho = self.radius(self.x_i, self.x_j) \n    R = jnp.sqrt(Rho[..., None]**2 + self.Z**2)\n    epsilon = self.emissivity(R, self.nh[..., None])\n\n    return epsilon\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.cube.EmissivityCube.__init__","title":"<code>__init__(data)</code>","text":"<p>Constructor for EmissivityCube using a Cluster object</p> Source code in <code>src/xsb_fluc/simulation/cube.py</code> <pre><code>def __init__(self, data: Cluster):\n    \"\"\"\n    Constructor for EmissivityCube using a Cluster object\n    \"\"\"\n\n    super(EmissivityCube, self).__init__()\n    self.emissivity = XrayEmissivity.from_data(data)\n    self.radius = EllipseRadius.from_data(data)\n    self.spatial_grid = SpatialGrid3D.from_data(data, crop_r_500=5)\n    self.nh = data.nh\n    self.x_i, self.x_j = self.spatial_grid.x_i, self.spatial_grid.y_i\n    self.Z = self.spatial_grid.Z\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.cube.FluctuationCube","title":"<code>FluctuationCube</code>","text":"<p>               Bases: <code>Module</code></p> <p>Compute a fluctuation cube for a given cluster. The density fluctuations are computed assuming a Gaussian Random Field defined with a turbulent power spectrum.</p> Source code in <code>src/xsb_fluc/simulation/cube.py</code> <pre><code>class FluctuationCube(hk.Module):\n    \"\"\"\n    Compute a fluctuation cube for a given cluster. The density fluctuations are computed\n    assuming a Gaussian Random Field defined with a turbulent power spectrum.\n    \"\"\"\n\n    def __init__(self, data: Cluster):\n        \"\"\"\n        Constructor for FluctuationCube using a Cluster object\n        \"\"\"\n\n        super(FluctuationCube, self).__init__()\n        self.power_spectrum = KolmogorovPowerSpectrum()\n        self.spatial_grid = SpatialGrid3D.from_data(data, crop_r_500=5)\n        self.fourier_grid = FourierGrid3D(self.spatial_grid)\n        self.K = self.fourier_grid.K.astype(np.float32)\n\n    def __call__(self) -&gt; jax.Array:\n        \"\"\"\n        Return the fluctuation cube.\n        \"\"\"\n\n        key = hk.next_rng_key()\n\n        field_spatial = random.normal(key, shape=self.spatial_grid.shape)\n        field_fourier = fft.rfftn(field_spatial)*jnp.sqrt(self.power_spectrum(self.K)/self.spatial_grid.pixsize**3)\n        field_spatial = fft.irfftn(field_fourier, s=self.spatial_grid.shape)\n\n        return field_spatial\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.cube.FluctuationCube.__call__","title":"<code>__call__()</code>","text":"<p>Return the fluctuation cube.</p> Source code in <code>src/xsb_fluc/simulation/cube.py</code> <pre><code>def __call__(self) -&gt; jax.Array:\n    \"\"\"\n    Return the fluctuation cube.\n    \"\"\"\n\n    key = hk.next_rng_key()\n\n    field_spatial = random.normal(key, shape=self.spatial_grid.shape)\n    field_fourier = fft.rfftn(field_spatial)*jnp.sqrt(self.power_spectrum(self.K)/self.spatial_grid.pixsize**3)\n    field_spatial = fft.irfftn(field_fourier, s=self.spatial_grid.shape)\n\n    return field_spatial\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.cube.FluctuationCube.__init__","title":"<code>__init__(data)</code>","text":"<p>Constructor for FluctuationCube using a Cluster object</p> Source code in <code>src/xsb_fluc/simulation/cube.py</code> <pre><code>def __init__(self, data: Cluster):\n    \"\"\"\n    Constructor for FluctuationCube using a Cluster object\n    \"\"\"\n\n    super(FluctuationCube, self).__init__()\n    self.power_spectrum = KolmogorovPowerSpectrum()\n    self.spatial_grid = SpatialGrid3D.from_data(data, crop_r_500=5)\n    self.fourier_grid = FourierGrid3D(self.spatial_grid)\n    self.K = self.fourier_grid.K.astype(np.float32)\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.mexican_hat","title":"<code>xsb_fluc.simulation.mexican_hat</code>","text":""},{"location":"references/simulation/#xsb_fluc.simulation.mexican_hat.MexicanHat","title":"<code>MexicanHat</code>","text":"<p>               Bases: <code>Module</code></p> <p>Mexican Hat filter for the power spectrum, using the implementation of Ar\u00e9valo et al. 2012.</p> Source code in <code>src/xsb_fluc/simulation/mexican_hat.py</code> <pre><code>class MexicanHat(hk.Module):\n    \"\"\"\n    Mexican Hat filter for the power spectrum, using the implementation of Ar\u00e9valo et al. 2012.\n    \"\"\"\n\n    def __init__(self, data, mask=None):\n        \"\"\"\n        Constructor for the MexicanHat class.\n\n        Parameters:\n            data (Cluster): Cluster object containing the data.\n            mask (np.ndarray): Mask to apply to the data.\n\n        !!! note\n            The `PowerSpectrum`class is a `Cluster` oriented wrapper around this class.\n        \"\"\"\n        super(MexicanHat, self).__init__()\n        self.mexican_hat = MexicanHatMask.from_data(data, mask=mask)\n        self.pixsize = self.mexican_hat.pixsize\n        self.epsilon = self.mexican_hat.epsilon\n        self.ratio = 1./np.sum(mask)\n        self.Y = jnp.pi \n\n    def __call__(self, img, scale):\n        \"\"\"\n        Computes the Mexican Hat filter for a given scale.\n\n        Parameters:\n            img (np.ndarray): Image to filter.\n            scale (float): Scale of the filter.\n        \"\"\"\n\n        img_convolved = self.mexican_hat(img, scale)\n        k = 1/scale\n\n        return jnp.sum(img_convolved**2)/(self.epsilon**2*self.Y*k**2)*self.ratio#/self.pixsize**2\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.mexican_hat.MexicanHat.__call__","title":"<code>__call__(img, scale)</code>","text":"<p>Computes the Mexican Hat filter for a given scale.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ndarray</code> <p>Image to filter.</p> required <code>scale</code> <code>float</code> <p>Scale of the filter.</p> required Source code in <code>src/xsb_fluc/simulation/mexican_hat.py</code> <pre><code>def __call__(self, img, scale):\n    \"\"\"\n    Computes the Mexican Hat filter for a given scale.\n\n    Parameters:\n        img (np.ndarray): Image to filter.\n        scale (float): Scale of the filter.\n    \"\"\"\n\n    img_convolved = self.mexican_hat(img, scale)\n    k = 1/scale\n\n    return jnp.sum(img_convolved**2)/(self.epsilon**2*self.Y*k**2)*self.ratio#/self.pixsize**2\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.mexican_hat.MexicanHat.__init__","title":"<code>__init__(data, mask=None)</code>","text":"<p>Constructor for the MexicanHat class.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Cluster</code> <p>Cluster object containing the data.</p> required <code>mask</code> <code>ndarray</code> <p>Mask to apply to the data.</p> <code>None</code> <p>Note</p> <p>The <code>PowerSpectrum</code>class is a <code>Cluster</code> oriented wrapper around this class.</p> Source code in <code>src/xsb_fluc/simulation/mexican_hat.py</code> <pre><code>def __init__(self, data, mask=None):\n    \"\"\"\n    Constructor for the MexicanHat class.\n\n    Parameters:\n        data (Cluster): Cluster object containing the data.\n        mask (np.ndarray): Mask to apply to the data.\n\n    !!! note\n        The `PowerSpectrum`class is a `Cluster` oriented wrapper around this class.\n    \"\"\"\n    super(MexicanHat, self).__init__()\n    self.mexican_hat = MexicanHatMask.from_data(data, mask=mask)\n    self.pixsize = self.mexican_hat.pixsize\n    self.epsilon = self.mexican_hat.epsilon\n    self.ratio = 1./np.sum(mask)\n    self.Y = jnp.pi \n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.mexican_hat.MexicanHatMask","title":"<code>MexicanHatMask</code>","text":"<p>               Bases: <code>Module</code></p> <p>Auxiliary class for the MexicanHat class. Handle the convolution in Fourier space, the padding, etc.</p> Source code in <code>src/xsb_fluc/simulation/mexican_hat.py</code> <pre><code>class MexicanHatMask(hk.Module):\n    \"\"\"\n    Auxiliary class for the MexicanHat class. Handle the convolution in Fourier space,\n    the padding, etc.\n    \"\"\"\n\n    def __init__(self, shape, mask=None, pixsize=0.005):\n        super(MexicanHatMask, self).__init__()\n\n        self.pixsize = pixsize \n        self.epsilon = 1e-3 \n        self.pad_size = 50\n        self.mask = jnp.pad(mask, self.pad_size)\n\n        kx = fft.fftfreq(shape[0] + 2*self.pad_size, d=self.pixsize)\n        ky = fft.rfftfreq(shape[1]+ 2*self.pad_size, d=self.pixsize)\n        KX, KY = jnp.meshgrid(kx, ky, indexing='ij')\n        self.K = (KX**2 + KY**2)**(1/2)\n\n    @classmethod\n    def from_data(cls, data: Cluster, mask=None):\n\n        if mask is None:\n            mask = data.exp &gt; 0.\n\n        return cls(mask.shape, mask=mask, pixsize=(data.kpc_per_pixel/data.r_500).to(1/u.pixel).value)\n\n    def fourier_kernel(self, sigma):\n\n        return jnp.exp(-2*(jnp.pi*self.K*sigma)**2)\n\n    def gaussian_blur(self, to_blur, sigma):\n\n        blurred_img = fft.irfft2(fft.rfft2(to_blur)*self.fourier_kernel(sigma), s=to_blur.shape)\n        return blurred_img#[self.pad_size:-self.pad_size, self.pad_size:-self.pad_size]\n\n    def filter(self, img, sigma):\n\n        img_masked = jnp.pad(img, self.pad_size) * self.mask\n        gsigma1 = self.gaussian_blur(img_masked, sigma*(1+self.epsilon)**(-1/2))\n        gsigma2 = self.gaussian_blur(img_masked, sigma*(1+self.epsilon)**(+1/2))\n        # FFT-convolve mask with the two scales\n        gmask1 = self.gaussian_blur(self.mask, sigma*(1+self.epsilon)**(-1/2))\n        gmask2 = self.gaussian_blur(self.mask, sigma*(1+self.epsilon)**(+1/2))\n        # Eq. 6 of Arevalo et al. 2012\n\n        r1 = jnp.where(gmask1 != 0., gsigma1/gmask1, 0.)\n        r2 = jnp.where(gmask2 != 0., gsigma2/gmask2, 0.)\n\n        return (r1 - r2)*self.mask\n\n    def __call__(self, img, scale):\n\n        k = 1/scale\n\n        #Ar\u00e9valo &amp; al A5\n        sigma = 1 / jnp.sqrt(2 * jnp.pi ** 2) / k\n        convolved_img = self.filter(img, sigma)\n\n        return convolved_img\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.power_spectrum","title":"<code>xsb_fluc.simulation.power_spectrum</code>","text":""},{"location":"references/simulation/#xsb_fluc.simulation.power_spectrum.PowerSpectrum","title":"<code>PowerSpectrum</code>","text":"<p>               Bases: <code>Module</code></p> <p>Compute the power spectrum using the Mexican Hat filter for <code>Cluster</code>data.</p> Source code in <code>src/xsb_fluc/simulation/power_spectrum.py</code> <pre><code>class PowerSpectrum(hk.Module):\n    \"\"\"\n    Compute the power spectrum using the Mexican Hat filter for `Cluster`data.\n    \"\"\"\n\n    def __init__(self, data, mask=None):\n        \"\"\"\n        Constructor for the PowerSpectrum class.\n\n        Parameters:\n            data (Cluster): Cluster object containing the data.\n            mask (np.ndarray): Mask to apply to the data.\n        \"\"\"\n        super(PowerSpectrum, self).__init__()\n        self.mexican_hat = MexicanHat(data, mask=mask)\n\n    def __call__(self, image, scales):\n        \"\"\"\n        Computes the power spectrum for a given image and scales.\n\n        Parameters:\n            image (np.ndarray): Image to compute the power spectrum of.\n            scales (np.ndarray): Scales to compute the power spectrum at.\n        \"\"\"\n\n        return hk.vmap(lambda s: self.mexican_hat(image, s), split_rng=False)(scales)\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.power_spectrum.PowerSpectrum.__call__","title":"<code>__call__(image, scales)</code>","text":"<p>Computes the power spectrum for a given image and scales.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>Image to compute the power spectrum of.</p> required <code>scales</code> <code>ndarray</code> <p>Scales to compute the power spectrum at.</p> required Source code in <code>src/xsb_fluc/simulation/power_spectrum.py</code> <pre><code>def __call__(self, image, scales):\n    \"\"\"\n    Computes the power spectrum for a given image and scales.\n\n    Parameters:\n        image (np.ndarray): Image to compute the power spectrum of.\n        scales (np.ndarray): Scales to compute the power spectrum at.\n    \"\"\"\n\n    return hk.vmap(lambda s: self.mexican_hat(image, s), split_rng=False)(scales)\n</code></pre>"},{"location":"references/simulation/#xsb_fluc.simulation.power_spectrum.PowerSpectrum.__init__","title":"<code>__init__(data, mask=None)</code>","text":"<p>Constructor for the PowerSpectrum class.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Cluster</code> <p>Cluster object containing the data.</p> required <code>mask</code> <code>ndarray</code> <p>Mask to apply to the data.</p> <code>None</code> Source code in <code>src/xsb_fluc/simulation/power_spectrum.py</code> <pre><code>def __init__(self, data, mask=None):\n    \"\"\"\n    Constructor for the PowerSpectrum class.\n\n    Parameters:\n        data (Cluster): Cluster object containing the data.\n        mask (np.ndarray): Mask to apply to the data.\n    \"\"\"\n    super(PowerSpectrum, self).__init__()\n    self.mexican_hat = MexicanHat(data, mask=mask)\n</code></pre>"}]}